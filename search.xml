<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[go-cache源码阅读笔记]]></title>
    <url>%2F2018%2F12%2F28%2Fgo-cache%E6%BA%90%E7%A0%81%E9%98%85%E8%AF%BB%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[自己经常使用 map 加上互斥锁来处理缓存， 很久之前就在 github 上发现 go-cache 这个项目，今天重新看到它，发现它已经 2000+star 了。 扫了一下代码，发现代码量很少，就 clone 下来看看。 go-cache 实际代码就两个文件–cache.go 和 shared.go,其中 shared.go 是作者打算在大缓存数据下使用 hash 算法提升缓存的读写速度的，实际上也未对外 export，创建 sharedCache 的函数名也是小写的。 cache 很简单，只有 map[string]Item 和锁。其中 Item 的结构为 1234type Item struct &#123; Object interface&#123;&#125; Expiration int64&#125; Object 存储数据，Expiration 存储数据过期时间。创建 cache 的时候会创建一个清理器来清理过期的数据 1234567891011121314func newCacheWithJanitor(de time.Duration, ci time.Duration, m map[string]Item) *Cache &#123; c := newCache(de, m) // This trick ensures that the janitor goroutine (which--granted it // was enabled--is running DeleteExpired on c forever) does not keep // the returned C object from being garbage collected. When it is // garbage collected, the finalizer stops the janitor goroutine, after // which c can be collected. C := &amp;Cache&#123;c&#125; if ci &gt; 0 &#123; runJanitor(c, ci) runtime.SetFinalizer(C, stopJanitor) &#125; return C&#125; 注意 runtime.SetFinalizer()这个函数，之前没用过。这是是在  程序垃圾回收(garbage collection)时执行指定函数。 shared.go 是创建一个 shardedCache， 包含多个 cache，通过 hash 算法(djb33)选择 cache 存取数据. 123456type shardedCache struct &#123; seed uint32 m uint32 cs []*cache janitor *shardedJanitor&#125; sharedCache 没有使用 go 的”hash/fnv”中的 hash.Hash 函数，使用的是自己写的 hash 算法，并称自己的 hash 算法 djb33 比 fnv 的快 5 倍 。 12345678910111213141516171819202122232425262728293031// djb2 with better shuffling. 5x faster than FNV with the hash.Hash overhead.func djb33(seed uint32, k string) uint32 &#123; var ( l = uint32(len(k)) d = 5381 + seed + l i = uint32(0) ) // Why is all this 5x faster than a for loop? if l &gt;= 4 &#123; for i &lt; l-4 &#123; d = (d * 33) ^ uint32(k[i]) d = (d * 33) ^ uint32(k[i+1]) d = (d * 33) ^ uint32(k[i+2]) d = (d * 33) ^ uint32(k[i+3]) i += 4 &#125; &#125; switch l - i &#123; case 1: case 2: d = (d * 33) ^ uint32(k[i]) case 3: d = (d * 33) ^ uint32(k[i]) d = (d * 33) ^ uint32(k[i+1]) case 4: d = (d * 33) ^ uint32(k[i]) d = (d * 33) ^ uint32(k[i+1]) d = (d * 33) ^ uint32(k[i+2]) &#125; return d ^ (d &gt;&gt; 16)&#125; 注意，创建 seed 代码 12345678910max := big.NewInt(0).SetUint64(uint64(math.MaxUint32))rnd, err := rand.Int(rand.Reader, max)var seed uint32if err != nil &#123; os.Stderr.Write([]byte("WARNING: go-cache's newShardedCache failed to read from the system CSPRNG (/dev/urandom or equivalent.) Your system's security may be compromised. Continuing with an insecure seed.\n")) seed = insecurerand.Uint32()&#125; else &#123; seed = uint32(rnd.Uint64())&#125; 引入的包是”crypto/rand” 和 insecurerand “math/rand”。 记得以后使用”crypto/rand” 来  构造随机数，安全些。]]></content>
      <categories>
        <category>Go学习小记</category>
      </categories>
      <tags>
        <tag>源码阅读</tag>
        <tag>笔记</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用gRPC交互]]></title>
    <url>%2F2017%2F09%2F20%2F%E4%BD%BF%E7%94%A8gRPC%E4%BA%A4%E4%BA%92%2F</url>
    <content type="text"><![CDATA[在.protoc中定义gRPC接口：1234567syntax = &quot;proto3&quot;;package example;service FormatData &#123; rpc DoFormat(Data) returns (Data)&#123;&#125;&#125;message Data &#123; string text = 1; 使用protoc将.protoc转化为你想要的语言的文件，方便调动 。编译器protoc的下载地址:https://github.com/google/protobuf/releases/tag/v3.4.1 Windows的版本:https://github.com/google/protobuf/releases/download/v3.4.0/protoc-3.4.0-win32.zip 使用protoc将.proto文件转为对应语言的文件。如果你想要python的协议文件的话，则将参数设置为–python_out:protoc -I=./ –python_out=./ ./rpc.proto 若是Golang的话，则为:protoc -I=./ –go_out=./ ./rpc.proto 使用Python的话，可以:1234pip install grpciopip install protobufpip install grpcio-toolspython -m grpc_tools.protoc -I../../protos --python_out=. --grpc_python_out=. ../../protos/helloworld.proto proto3和proto2语法不一样，基本上是关键字变少了。 例子]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>gRPC</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(翻译)For Range Semantics]]></title>
    <url>%2F2017%2F08%2F07%2F(%E7%BF%BB%E8%AF%91)For%20Range%20Semantics%2F</url>
    <content type="text"><![CDATA[原文是《For Range Semantics》 序章为了更好的理解这篇文章中展现的内容，你应该先阅读以下文章： 四篇文章的索引： Language Mechanics On Stacks And Pointers Language Mechanics On Escape Analysis Language Mechanics On Memory Profiling Design Philosophy On Data And Semantics 值的概念和指针的语义在 Go 中无处不在。正如之前的文章中说的那样，语义一致性对于完整性和可读性至关重要。它让开发人员，随着代码库的增长，保持一个强大的代码库的心理模型。它可以尽可能减少错误，副作用和未知的表现。 引言这这篇文章中，我将会探索在 Go 中 for range 语法块同时提供值和指针两种语义形式。我会教你语义的使用并展示给你这个语义如何衍生至更深层次。然后，我会使用一个简单的例子，来展示使用这些语义会出现的错误。 语言技巧用这段代码来展示 for range 循环的 value 语义格式。 https://play.golang.org/p/_CWCAF6ge3 Listing1 12345678910111213141516171819202101 package main0203 import "fmt"0405 type user struct &#123;06 name string07 email string08 &#125;0910 func main() &#123;11 users := []user&#123;12 &#123;"Bill", "bill@email.com"&#125;,13 &#123;"Lisa", "lisa@email.com"&#125;,14 &#123;"Nancy", "nancy@email.com"&#125;,15 &#123;"Paul", "paul@email.com"&#125;,16 &#125;1718 for i, u := range users &#123;19 fmt.Println(i, u)20 &#125;21 &#125; 在图 1 中，程序声明了 user 类型，创建了四个 user 值并且列出每一个 user 的信息。18 行的 for range 循环使用 value 语义。因为在每一个迭代中，创建切片中的原始的 user 值的拷贝，并在循环中操作这个拷贝值。实际上，调用 Println 创建了循环体中的第二个拷贝。如果要将值语义用于 user 值，这就是你想要的。 如果你想要使用指针，那么 for range 循环将会是这样。 Listing 2 12318 for i := range users &#123;19 fmt.Println(i, users[i])20 &#125; 现在循环已经修改成指针语义。循环中的代码不再操作它自己的复制，而是操作存在切片中的原始的 user 值。但是调用 Println 仍然使用值语义，传递的是一个拷贝。 为了修正这个需求，我们最后修改一下。 Listing 3 12318 for i := range users &#123;19 fmt.Println(i, &amp;users[i])20 &#125; 现在就是始终使用的 user 数据的指针技巧了。 Listing4 一步步展示了值和指针语义作为参考 Listing 4 1234 // Value semantics. // Pointer semantics.18 for i, u := range users &#123; for i := range users &#123;19 fmt.Println(i, u) fmt.Println(i, &amp;users[i])20 &#125; &#125; 更深层次的技巧比这更深层次的语言技巧。让我们看一下下面 listing5 的程序。这段程序初始化了字符串数组，迭代这些字符串并且每次迭代的时候都改变 index 为 1 的字符串的值。 Listing 5 1234567891011121314151601 package main0203 import "fmt"0405 func main() &#123;06 five := [5]string&#123;"Annie", "Betty", "Charley", "Doug", "Edward"&#125;07 fmt.Printf("Bfr[%s] : ", five[1])0809 for i := range five &#123;10 five[1] = "Jack"1112 if i == 1 &#123;13 fmt.Printf("Aft[%s]\n", five[1])14 &#125;15 &#125;16 &#125; 这段程序将会输出什么呢？ Listing 6 1Bfr[Betty] : Aft[Jack] 正如你所希望的那样，第 10 行代码已经改变了 index 为 1 的字符串的值，你可以从输出的结果中看到。这段代码使用了 for range 的指针语义版本。下面的代码将会使用 for range 循环的值语义版本。 https://play.golang.org/p/opSsIGtNU1 Listing 7 1234567891011121314151601 package main0203 import "fmt"0405 func main() &#123;06 five := [5]string&#123;"Annie", "Betty", "Charley", "Doug", "Edward"&#125;07 fmt.Printf("Bfr[%s] : ", five[1])0809 for i, v := range five &#123;10 five[1] = "Jack"1112 if i == 1 &#123;13 fmt.Printf("v[%s]\n", v)14 &#125;15 &#125;16 &#125; 在每一个循环的迭代中，代码再次改变了 index 1 的字符串的值，但是这次输出的结果却不一样。 Listing 8 1Bfr[Betty] : v[Betty] 你可以看到这次 for range 确实使用了值语义。for range 迭代了它自己的对于数组的拷贝。这就是为什么改变的内容在输出的结果中看不到。 当使用值语义格式迭代切片的时候，就会得到切片的头部的拷贝。这就是为什么我 listing 9 不会产生 panic 的原因。 https://play.golang.org/p/OXhdsneBec Listing 9 1234567891011121314151617181901 package main0203 import "fmt"0405 func main() &#123;06 five := []string&#123;"Annie", "Betty", "Charley", "Doug", "Edward"&#125;0708 for _, v := range five &#123;09 five = five[:2]10 fmt.Printf("v[%s]\n", v)11 &#125;12 &#125;Output:v[Annie]v[Betty]v[Charley]v[Doug]v[Edward] 如果你想到 09 行你就会知道，虽然切片在循环中已经被缩短到长度为 2，但是循环值操作属于它自己的切片的拷贝。这让循环可以使用原先长度来迭代因为备份的数组仍是完整的。 如果代码使用 for range 的指针语义格式，那么这个代码会产生 panic。 https://play.golang.org/p/k5a73PHaka Listing 10 12345678910111213141516171819202101 package main0203 import "fmt"0405 func main() &#123;06 five := []string&#123;"Annie", "Betty", "Charley", "Doug", "Edward"&#125;0708 for i := range five &#123;09 five = five[:2]10 fmt.Printf("v[%s]\n", five[i])11 &#125;12 &#125;Output:v[Annie]v[Betty]panic: runtime error: index out of rangegoroutine 1 [running]:main.main() /tmp/sandbox688667612/main.go:10 +0x140 for range 在迭代前就获取了切片的长度，但是在循环的时候长度改变了。在第三次迭代的时候，循环体尝试访问与切片长度关联不上元素。 混合语义下面展示一个完整的错误例子。这段代码混合使用 user 类型的语义，并引起错误。 https://play.golang.org/p/L_WmUkDYFJ Listing 11 1234567891011121314151617181920212223242526272829303101 package main0203 import "fmt"0405 type user struct &#123;06 name string07 likes int08 &#125;0910 func (u *user) notify() &#123;11 fmt.Printf("%s has %d likes\n", u.name, u.likes)12 &#125;1314 func (u *user) addLike() &#123;15 u.likes++16 &#125;1718 func main() &#123;19 users := []user&#123;20 &#123;name: "bill"&#125;,21 &#123;name: "lisa"&#125;,22 &#125;2324 for _, u := range users &#123;25 u.addLike()26 &#125;2728 for _, u := range users &#123;29 u.notify()30 &#125;31 &#125; 这个例子不是很做作。在 05 行声明了 user 类型，选择指针语义实现 user 类型的方法集。在 main 程序中，for range 循环体使用了值语义，并且每一个 user 都使用了 addlock()方法。第二个循环体用来 notify 每一个 user，同样使用了值语义。 Listing 12 12bill has 0 likeslisa has 0 likes 输出表明没有 like 增加。我一直强调你应该为给定类型选择一个语义，并坚持使用该类型的数据做所有事情。 下面是代码如何注意与 user 类型的指针语义保持一致的方法。 https://play.golang.org/p/GwAnyBNqPz Listing 13 123456789101112131415161718192021222324252627282930313233343501 package main0203 import "fmt"0405 type user struct &#123;06 name string07 likes int08 &#125;0910 func (u *user) notify() &#123;11 fmt.Printf("%s has %d likes\n", u.name, u.likes)12 &#125;1314 func (u *user) addLike() &#123;15 u.likes++16 &#125;1718 func main() &#123;19 users := []user&#123;20 &#123;name: "bill"&#125;,21 &#123;name: "lisa"&#125;,22 &#125;2324 for i := range users &#123;25 users[i].addLike()26 &#125;2728 for i := range users &#123;29 users[i].notify()30 &#125;31 &#125;// Output:bill has 1 likeslisa has 1 likes 总结值和指针语义是 Go 语言编程的很大一部分，正如我所展示的，整合进 for range 循环中。当使用 for range 循环的时候，确定你使用了你迭代的给定类型的正确的格式。尽量不要混合使用语义，如果你不注意的话，使用 for range 的时候很容易这么做。 语言赋予你这种选择语义的能力，并能始终如一地工作。这是你想要充分利用的东西。我想让你决定每种类型使用什么语义并保持一致。你对一个数据的语义越一致，您的代码库就会越好。如果您有一个很好的理由来改变语义，那么就将其广泛地记录下来。]]></content>
      <categories>
        <category>Go学习小记</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>语法</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(翻译)go-styleguide]]></title>
    <url>%2F2017%2F08%2F02%2F(%E7%BF%BB%E8%AF%91)go-styleguide%2F</url>
    <content type="text"><![CDATA[原文在这里： https://github.com/bahlo/go-styleguide/blob/master/README.md Go Styleguide Go的风格指南This serves as a supplement toEffective Go, based on years ofexperience and inspiration/ideas from conference talks. 这篇文章作为Effective Go的补充，这是根据多年的经验和来自会议讨论的灵感/想法来写的。 Table of contents 目录 Add context to errors 给errors添加上下文 Dependency managemenet 依赖管理 Use dep 使用dep Use Semantic Versioning 使用Semantic Versioning Avoid gopkg.in 避免使用gopkg.in Structured logging 结构化的日志 Avoid global variables 避免全局变量 Testing 测试 Use assert-libraries 使用assert-libraries Use table-driven tests 使用table-driven测试 Avoid mocks 避免模拟 Avoid DeepEqual 避免DeepEqual Avoid testing unexported funcs 避免测试不能外部使用的函数 Use linters 使用linters Use gofmt 使用gofmt Avoid side effects 避免使用side效果 Favour pure funcs 偏爱纯函数 Don’t over-interface 不要过度接口话 Don’t under-package Handle signals 处理信号 Divide imports 划分imports Avoid unadorned return 避免不终止的return Use package comment 使用包注释 Avoid empty interface 避免空接口 Main first Use internal packages 使用接口包 Avoid helper/util 避免 helper/util Embed binary data 内置二进制数据 Use decorator pattern 使用装饰模式 Add context to errors 给errors添加上下文Don’t:1234file, err := os.Open("foo.txt")if err != nil &#123; return err&#125; Using the approach above can lead to unclear error messages because of missingcontext. 使用上面的方法会因为缺少上下文而产生不明确的错误消息。 Do:12345678import "github.com/pkg/errors" // for example// ...file, err := os.Open("foo.txt")if err != nil &#123; return errors.Wrap(err, "open foo.txt failed")&#125; Wrapping errors with a custom message provides context as it gets propagated upthe stack. 用通用的消息包裹错误信息从而提供上下文信息，可以在堆栈返回时传递此错误。 This does not always make sense. 这不总是有意义 If you’re unsure if the context of a returned error is at all times sufficient,wrap it.Make sure the root error is still accessible somehow for type checking. 如果您不确定返回的错误的上下文是否足够,那就加上上下文信息。确保根错误通过某种方式进行类型检查时仍然有意义。 Dependency management 依赖管理Use dep 使用depUse dep, since it’s production ready and willsoon become part of the toolchain. 使用dep,因为它已经是生成级工具并且很快就会成为工具链的一部分。– Sam Boyer at GopherCon 2017 Use Semantic Versioning 使用Semantic VersioningSince dep can handle versions, tag your packages usingSemantic Versioning. 因为dep可以处理版本，所以使用Semantic Versioning给你的包加上标签 Avoid gopkg.in 避免使用gopkg.inWhile gopkg.in is a great tool and was reallyuseful, it tags one version and is not meant to work with dep.Prefer direct import and specify version in Gopkg.toml. 尽管gopkg.in是非常好的工具并且真的很好用，但是它只标注一个版本并且使用dep。应该直接import并在Gopkg.toml指定版本 Structured logging 结构化loggingDon’t:123log.Printf("Listening on :%d", port)http.ListenAndServe(fmt.Sprintf(":%d", port), nil)// 2017/07/29 13:05:50 Listening on :80 Do:123456789101112import "github.com/uber-go/zap" // for example// ...logger, _ := zap.NewProduction()defer logger.Sync()logger.Info("Server started", zap.Int("port", port), zap.String("env", env),)http.ListenAndServe(fmt.Sprintf(":%d", port), nil)// &#123;"level":"info","ts":1501326297.511464,"caller":"Desktop/structured.go:17","msg":"Server started","port":80,"env":"production"&#125; This is a harmless example, but using structured logging makes debugging and logparsing easier. 这是没有损害的例子，但是使用结构化的日志可以使调试和解析log更简单 Avoid global variables 避免使用全局变量Don’t:1234567891011var db *sql.DBfunc main() &#123; db = // ... http.HandleFunc("/drop", DropHandler) // ...&#125;func DropHandler(w http.ResponseWriter, r *http.Request) &#123; db.Exec("DROP DATABASE prod")&#125; Global variables make testing and readability hard and every method has accessto them (even those, that don’t need it). 全局变量使得测试和可读性变得更加困难。每一个方法都能访问他（即使那些不需要它的方法） Do:1234567891011func main() &#123; db := // ... http.HandleFunc("/drop", DropHandler(db)) // ...&#125;func DropHandler(db *sql.DB) http.HandleFunc &#123; return func (w http.ResponseWriter, r *http.Request) &#123; db.Exec("DROP DATABASE prod") &#125;&#125; Use higher-order functions instead of global variables to inject dependenciesaccordingly. 因此使用高阶函数取代全局变量来加入依赖性。 Testing 测试Use assert-libraries 使用assert-librariesDon’t:1234567func TestAdd(t *testing.T) &#123; actual := 2 + 2 expected := 4 if (actual != expected) &#123; t.Errorf("Expected %d, but got %d", expected, actual) &#125;&#125; Do:1234567import "github.com/stretchr/testify/assert" // for examplefunc TestAdd(t *testing.T) &#123; actual := 2 + 2 expected := 4 assert.Equal(t, expected, actual)&#125; Using assert libraries makes your tests more readable, requires less code andprovides consistent error output. 使用断言库让你的测试更有可读性，代码量更少并且提供一致的错误输出。 Use table driven tests 使用表驱动测试Don’t:123456func TestAdd(t *testing.T) &#123; assert.Equal(t, 1+1, 2) assert.Equal(t, 1+-1, 0) assert.Equal(t, 1, 0, 1) assert.Equal(t, 0, 0, 0)&#125; The above approach looks simpler, but it’s much harder to find a failing case,especially when having hundreds of cases. 以上的方法看起来更简单，但是它更难找到错误样例，尤其是在有几百个样例的时候。 Do:12345678910111213141516func TestAdd(t *testing.T) &#123; cases := []struct &#123; A, B, Expected int &#125;&#123; &#123;1, 1, 2&#125;, &#123;1, -1, 0&#125;, &#123;1, 0, 1&#125;, &#123;0, 0, 0&#125;, &#125; for _, tc := range cases &#123; t.Run(fmt.Sprintf("%d + %d", tc.A, tc.B), func(t *testing.T) &#123; assert.Equal(t, t.Expected, tc.A+tc.B) &#125;) &#125;&#125; Using table driven tests in combination with subtests gives you direct insight about which case is failing and which cases are tested.– Mitchell Hashimoto at GopherCon 2017 使用表驱动测试结合子测试让你直观的看到哪一个册书样例失败了，哪个测试样例正在执行 Avoid mocksDon’t:1234func TestRun(t *testing.T) &#123; mockConn := new(MockConn) run(mockConn)&#125; Do:12345678910111213141516func TestRun(t *testing.T) &#123; ln, err := net.Listen("tcp", "127.0.0.1:0") t.AssertNil(t, err) var server net.Conn go func() &#123; defer ln.Close() server, err := ln.Accept() t.AssertNil(t, err) &#125;() client, err := net.Dial("tcp", ln.Addr().String()) t.AssertNil(err) run(client)&#125; Only use mocks if not otherwise possible, favor real implementations. – Mitchell Hashimoto at GopherCon 2017 只有在没有其他机会的时候使用mock，否则尽量使用真实实现。 Avoid DeepEqual 避免DeepEqualDon’t:1234567891011type myType struct &#123; id int name string irrelevant []byte&#125;func TestSomething(t *testing.T) &#123; actual := &amp;myType&#123;/* ... */&#125; expected := &amp;myType&#123;/* ... */&#125; assert.True(t, reflect.DeepEqual(expected, actual))&#125; Do:123456789101112131415161718type myType struct &#123; id int name string irrelevant []byte&#125;func (m *myType) testString() string &#123; return fmt.Sprintf("%d.%s", m.id, m.name)&#125;func TestSomething(t *testing.T) &#123; actual := &amp;myType&#123;/* ... */&#125; expected := &amp;myType&#123;/* ... */&#125; if actual.testString() != expected.testString() &#123; t.Errorf("Expected '%s', got '%s'", expected.testString(), actual.testString()) &#125; // or assert.Equal(t, actual.testString(), expected.testString())&#125; Using testString() for comparing structs helps on complex structs with many fields that are not relevant for the equality check.This approach only makes sense for very big or tree-like structs.– Mitchell Hashimoto at GopherCon 2017 使用 testing()来比较结构体，在结构体很复杂且结构体中的许多字段不用于比较相等的时候很有用。这个方法对于大结构体或者树状结构体很有用。 Avoid testing unexported funcs 不要测试不可导出的函数Only test unexported funcs if you can’t access a path via exported funcs. Since they are unexported, they are prone to change. 只有当你不能通过导出的函数访问不可导出函数的时候，测试不可导出的函数。因为他们不能被导出，所有会改变。 Use linters 使用lintersUse linters (e.g. gometalinter) tolint your projects before committing. 在你的项目提交之前使用linters检查代码 Use gofmt 使用gofmtOnly commit gofmt’d files, use -s to simplify code. 只提交gofmt后的文件，使用 -s 参数来简化代码。 Avoid side-effects 避免side-effectsDon’t:123func init() &#123; someStruct.Load()&#125; Side effects are only okay in special cases (e.g. parsing flags in a cmd). If you find no other way, rethink and refactor.Side effect只有在特殊情况下可以（例如在cmd中解析flags）。如果你想不到其他方法，重新想或者重构。 Favour pure funcs 尽量使用纯函数 In computer programming, a function may be considered a pure function if both of the following statements about the function hold: 在计算机编程中,如果函数包含以下的描述，则应该当做是一个纯函数： The function always evaluates the same result value given the same argument value(s). The function result value cannot depend on any hidden information or state that may change while program execution proceeds or between different executions of the program, nor can it depend on any external input from I/O devices. 函数总是在传递相同的参数时得出相同的值。函数的结果不依赖于程序执行过程中的任何隐藏的信息或者状态，也不依赖来自I/O设备的外部的输入。 Evaluation of the result does not cause any semantically observable side effect or output, such as mutation of mutable objects or output to I/O devices. 结果的计算不会导致任何明显的语义上的副作用或者输出，例如可变对象的变化或输出到输入/输出设备。 – Wikipedia Don’t:12345678func MarshalAndWrite(some *Thing) error &#123; b, err := json.Marshal(some) if err != nil &#123; return err &#125; return ioutil.WriteFile("some.thing", b, 0644)&#125; Do:123456// Marshal is a pure func (even though useless)func Marshal(some *Thing) ([]bytes, error) &#123; return json.Marshal(some)&#125;// ... This is obviously not possible at all times, but trying to make every possible func pure makes code more understandable and improves debugging. 显然不能任何时候都这么写，但是尽量使每一个函数都是纯函数，让代码更加易懂且易调试。 Don’t over-interface 不要过度接口化Don’t:1234567891011121314151617type Server interface &#123; Serve() error Some() int Fields() float64 That() string Are([]byte) error Not() []string Necessary() error&#125;func debug(srv Server) &#123; fmt.Println(srv.String())&#125;func run(srv Server) &#123; srv.Serve()&#125; Do:1234567891011type Server interface &#123; Serve() error&#125;func debug(v fmt.Stringer) &#123; fmt.Println(v.String())&#125;func run(srv Server) &#123; srv.Serve()&#125; Favour small interfaces and only expect the interfaces you need in your funcs. 使用更小的接口且在你的函数中(的形参中)只要求你需要的接口. Don’t under-packageDeleting or merging packages is fare more easier than splitting big ones up. When unsure if a package can be split, do it. 删除或者合并包比从中分离包简单的多。当你不确定一个包是否能被分离，那你可以去去试试看 Handle signals 处理信号Don’t:123456func main() &#123; for &#123; time.Sleep(1 * time.Second) ioutil.WriteFile("foo", []byte("bar"), 0644) &#125;&#125; Do:1234567891011121314151617181920212223func main() &#123; logger := // ... sc := make(chan os.Signal) done := make(chan bool) go func() &#123; for &#123; select &#123; case s := &lt;-sc: logger.Info("Received signal, stopping application", zap.String("signal", s.String())) break default: time.Sleep(1 * time.Second) ioutil.WriteFile("foo", []byte("bar"), 0644) &#125; &#125; done &lt;- true &#125;() signal.Notify(sc, os.Interrupt, os.Kill) &lt;-done // Wait for go-routine&#125; Handling signals allows us to gracefully stop our server, close open files and connections and therefore prevent file corruption among other things. 处理信号可以使用安全的退出服务，关闭打开的文件和连接。防止因为其他事情损坏文件。 Divide imports 分开 importsDon’t:1234567import ( "encoding/json" "github.com/some/external/pkg" "fmt" "github.com/this-project/pkg/some-lib" "os") Do:123456789import ( "encoding/json" "fmt" "os" "github.com/some/external/pkg" "github.com/this-project/pkg/some-lib") Dividing std, external and internal imports improves readability. 将std，外部和内部imports分开，提高可读性 Avoid unadorned return 避免不加修饰的returnDon’t:1234func run() (n int, err error) &#123; // ... return&#125; Do:1234func run() (n int, err error) &#123; // ... return n, err&#125; Named returns are good for documentation, unadorned returns are bad for readability and error-prone. 命名的返回值对于文档很有用，不加修饰的返回不利于可读性且易错 Use package comment 使用包注释Don’t:1package sub Do:1package sub // import "github.com/my-package/pkg/sth/else/sub" Adding the package comment adds context to the package and makes importing easy. 包注释给包添加了上下文，并使用导入更加容易。 Avoid empty interface 避免空的接口Don’t:123func run(foo interface&#123;&#125;) &#123; // ...&#125; Empty interfaces make code more complex and unclear, avoid them where you can. 空接口是代码更加的复杂，能不使用就不使用。 Main firstDon’t:1234567891011121314151617package main // import "github.com/me/my-project"func someHelper() int &#123; // ...&#125;func someOtherHelper() string &#123; // ...&#125;func Handler(w http.ResponseWriter, r *http.Reqeust) &#123; // ...&#125;func main() &#123; // ...&#125; Do:1234567891011121314151617package main // import "github.com/me/my-project"func main() &#123; // ...&#125;func Handler(w http.ResponseWriter, r *http.Reqeust) &#123; // ...&#125;func someHelper() int &#123; // ...&#125;func someOtherHelper() string &#123; // ...&#125; Putting main() first makes reading the file a lot more easier. Only the init() function should be above it. 将main函数放在最开始，可以使你阅读这个文件更加简单。只有init()函数应该放在main上面。 Use internal packages 使用内部包If you’re creating a cmd, consider moving libraries to internal/ to prevent import of unstable, changing packages. 如果你创建一个cmd，尝试将包放到internal/中，避免这个不稳定且经常改动的包被其他地方import Avoid helper/utilUse clear names and try to avoid creating a helper.go, utils.go or even package. 使用清楚的名字，尽量避免创建helper.go，utils.go这样的文件或者package Embed binary data 内置二进制数据To enable single-binary deployments, use tools to add templates and other staticassets to your binary(e.g. github.com/jteeuwen/go-bindata). 为了能够有单二进制文件部署，使用工具添加模板和其他静态文件资源到你的二进制文件中。 Use decorator pattern 使用装饰器1234567891011121314151617181920212223242526272829303132333435type Config struct &#123; port int timeout time.Duration&#125;type ServerOpt func(*Config)func WithPort(port int) ServerOpt &#123; return func(cfg *Config) &#123; cfg.port = port &#125;&#125;func WithTimeout(timeout time.Duration) ServerOpt &#123; return func(cfg *Config) &#123; cfg.timeout = timeout &#125;&#125;func startServer(opts ...ServerOpt) &#123; cfg := new(Config) for _, fn := range opts &#123; fn(cfg) &#125; // ...&#125;func main() &#123; // ... startServer( WithPort(8080), WithTimeout(1 * time.Second), )&#125;]]></content>
      <categories>
        <category>Go学习小记</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>风格</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Gugo！我自己写的简易静态博客生成器]]></title>
    <url>%2F2017%2F07%2F26%2FGugo%EF%BC%81%E6%88%91%E8%87%AA%E5%B7%B1%E5%86%99%E7%9A%84%E7%AE%80%E6%98%93%E9%9D%99%E6%80%81%E5%8D%9A%E5%AE%A2%E7%94%9F%E6%88%90%E5%99%A8%2F</url>
    <content type="text"><![CDATA[我自己使用Go写了一个简易的静态博客生成器。可以将使用markdown写的博客文章转换成html博客页面。写这篇文章的时候，已经实现了博客主页文章列表，博客文章展示，tag列表和分类列表。 我的github项目–gugo 缘起在看完并翻译writing%20a%20Static%20Blog%20Generator%20in%20Go/)了这篇文章之后，我就有了自己写一个静态博客的想法。 在此之前，我的博客使用的是hexo，看了不少hexo的document来学习使用hexo。为了使我的博客更加赏心悦目，我一直致力于更换hexo的theme，并乐此不疲。 偶然间从github的trending上看到hugo，第一反应是–“哎哟，不错哟”。我对其这么有好感的主要原因是hugo是用Go写的。然后我就去官方网站看hugo的–啧啧，Hugo的官网真是丑到爆！我直接下拉看themes，嗯，真丑。（我写这篇博客的时候，hugo提供的theme样例已经很多了，看起来还很不错） 所以，我虽然觉得hugo不错，但因为官方提供的theme样例丑的原因，而并没有使用hugo生成我的静态博客。虽然hugo只是一个静态博客生成器，和网站的theme并无太大关系，但是我一个theme的美观足以促使我使用这个项目。hugo没有代替hexo在我心中的地位，但是她也给了我很深的印象。 当看到《Writing a Static Blog Generator in Go》这篇文章的时候，我就表现出了极大的兴趣。这篇博客写的非常好，我迫不及待的翻译了这篇文章。让我受益匪浅。 原理静态博客原理很简单，其核心要素是：1. 解析yaml数据 2. 将markdown文件转成HTML文件 3. 模板渲染 4. 路由 解析yaml数据每篇文章都必须有Title，Date，Tags，Category数据，我们将这些数据称之为metadata。在每篇markdown的文章开头都加上yaml格式的metadata，以便我们获取这些信息。 解析markdown文件的内容时候，截取metadata数据并Unmarshal。在解析文件的时候，顺便检测more标签，当这个标签单独出现在一行的时候，就表示more之前的内容是概览内容。在首页展示的就是more之前的内容（概览）。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758func (p *Post) ParseMetaData() (err error) &#123; buf := bufio.NewReader(bytes.NewReader(p.sourceData)) metaData := []byte&#123;&#125; overview := []byte&#123;&#125; content := []byte&#123;&#125; metaStart := false metaFinished := false overviewFinished := false // get the data between the line only have "---" for true &#123; line, isPrefix, lineErr := buf.ReadLine() if lineErr != nil &#123; break &#125; for _, s := range []string&#123;"---", "--- ", " --- ", " ---", "----"&#125; &#123; if string(line) == s &#123; if metaStart == true &#123; metaFinished = true &#125; metaStart = true &#125; &#125; for _, s := range []string&#123;"&lt;!-- more --&gt;", "&lt;!-- more--&gt;", "&lt;!--more --&gt;"&#125; &#123; if strings.Contains(string(line), s) &#123; overviewFinished = true &#125; &#125; if !isPrefix &#123; line = append(line, []byte("\n")...) &#125; if metaStart &amp;&amp; !metaFinished &#123; metaData = append(metaData, line...) &#125; if metaFinished &amp;&amp; !overviewFinished &#123; overview = append(overview, line...) &#125; if metaFinished &#123; content = append(content, line...) &#125; &#125; if !metaFinished &#123; return fmt.Errorf("Cannot find the metadata of the post!") &#125; err = yaml.Unmarshal(metaData, p.Meta) if err != nil &#123; return &#125; if p.Meta.Title == "" &#123; return fmt.Errorf("The title of the post is empty!") &#125; if p.Meta.Date == "" &#123; return fmt.Errorf("The Date of the post is empty!") &#125; p.sourceData = content p.overviewData = overview return&#125; 将markdown文件转成HTML文件几乎每个主流的现代语言(nodejs,python,go)都有markdown转成HTML的包,直接调用包就可以将Markdown文件转成HTML文件了。我使用的是Go语言，使用blackfriday 包将Markdown转成html数据。1234567891011121314func (p *Post) Convert() (err error) &#123; p.htmlData = blackfriday.MarkdownCommon(p.sourceData) p.htmlData, err = p.fixHtmlData(p.htmlData) if err != nil &#123; return err &#125; p.overviewHtml = blackfriday.MarkdownCommon(p.overviewData) p.overviewHtml, err = p.fixHtmlData(p.overviewHtml) if err != nil &#123; return err &#125; return&#125; 为了使Markdown文件中的Code数据能够高亮，使用syntaxhighligh将代码的html高亮。 12345678910111213141516171819202122func (p *Post) fixHtmlData(data []byte) (newData []byte, err error) &#123; reader := bytes.NewReader(data) doc, err := goquery.NewDocumentFromReader(reader) if err != nil &#123; return newData, fmt.Errorf("Creating NewDocumentFromReader Err:%v", err) &#125; doc.Find("code[class*=\"language-\"]").Each(func(i int, s *goquery.Selection) &#123; oldCode := s.Text() formatted, _ := syntaxhighlight.AsHTML([]byte(oldCode)) s.Empty() s.AppendHtml(string(formatted)) &#125;) newDoc, err := doc.Html() if err != nil &#123; return newData, fmt.Errorf("Generating new html err: %v", err) &#125; // replace the html tags that we donnot need for _, tag := range []string&#123;"&lt;html&gt;", "&lt;/html&gt;", "&lt;head&gt;", "&lt;/head&gt;", "&lt;body&gt;", "&lt;/body&gt;"&#125; &#123; newDoc = strings.Replace(newDoc, tag, "", 1) &#125; return []byte(newDoc), err&#125; 模板渲染Markdown文件的数据只是页面展示里的文章内容。页面的布局，样式和页面的其他内容在模板中。我们需要做的就是将解析好的html数据放到模板中，然后渲染出我们想要的HTML。在这里我们只需要Go官方的”html/template”包就好了。 1234567891011121314151617181920// generate index.html by templatefunc GenerateIndexFile(t *template.Template, data interface&#123;&#125;, dir string) error &#123; if err := os.MkdirAll(dir, 0777); err != nil &#123; return fmt.Errorf("Create directory error:%v", err) &#125; f, err := os.Create(dir + "/index.html") if err != nil &#123; return fmt.Errorf("Creating file %s Err:%v", dir, err) &#125; defer f.Close() writer := bufio.NewWriter(f) if err := t.Execute(writer, data); err != nil &#123; return fmt.Errorf("Executing template Error: %v", err) &#125; if err := writer.Flush(); err != nil &#123; return fmt.Errorf("Writing file Err: %v", err) &#125; return nil&#125; 此时HTML文件就是显示的页面了。 路由静态博客的路由就是文件的目录路径。我将生成的HTML文件命名为index.html，因为路径下存在index.html的话，web服务器会默认加载路径下名为index.html的文件。我以文章的Date作为文章的路径。 首页就是在博客的根目录生成index.html，其内容就是将文章的列表放在index.tpl中渲染得到的数据。当首页展示不了太多的文章列表的时候，就需要分页。分页就是在根目录下建立page目录（这也就是page的路由），在page目录下建立index.html，内容同上。 Tags和Category的原理是一样的。建立Tags目录，目录中建立index.html，内容为Tags的列表。每一个tag都建立一个目录，目录下都有一个index.html，其内容是此tag的文章列表。 结语空想是不行的，要多学，多做，多练！不能再再再再再再堕落了！！！]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>yaml</tag>
        <tag>静态博客</tag>
        <tag>go</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(翻译)writing a Static Blog Generator in Go]]></title>
    <url>%2F2017%2F07%2F04%2F%E7%BF%BB%E8%AF%91-writing-a-Static-Blog-Generator-in-Go%2F</url>
    <content type="text"><![CDATA[翻译原文：https://zupzup.org/static-blog-generator-go/?utm_source=golangweekly&amp;utm_medium=emai Writing a Static Blog Generator in Go 使用Go写一个静态博客生成器A static-site-generator is a tool which, given some input (e.g. markdown) generates a fully static website using HTML, CSS and JavaScript. 一个静态网站生成器是一个使用HTML, CSS and JavaScript,将给予的输入文件（例如markdown）生成完整的静态网站 Why is this cool? Well, for one it’s a lot easier to host a static site and it’s also (usually) quite a bit faster and resource-friendly. Static sites aren’t the best choice for all use-cases, but for mostly non-interactive websites such as blogs they are great. 为什么这很Cool？是的，对于一个人来说，主持一个静态的网站要容易得多，而且(通常)也会更快，而且资源更友好。静态网站不是对所有情况都是最好的选择，但是对于大多数非交互网站比如博客，是非常好的。 In this post, I will describe the static blog generator I wrote in Go, which powers this blog. 在本文中，我将描述我使用Go编写的静态博客生成器，它为这个博客提供了强大的功能。 Motivation 动机You might be familiar with static-site-generators like the great Hugo, which has just about all the features one could hope for in regards to static site generation. 你可能对像Hugo这样的静态站点生成器很熟悉，它拥有关于静态站点生成的所有特性。 So why would I write another tool just like it with fewer capabilities? The reason was twofold. 所以我为什么写另外一个像它一样但功能更少的工具？原因有两个。 One reason was that I wanted to dive deeper into Go and a command-line-based static-site-generator seemed like a great playground to hone my skills. 一个原因是我想要深入学习Go，一个基于命令行的静态博客生成器似乎是一个磨练我技能的好地方。 The second reason was simply that I had never done it before. I’ve done my fair share of web-development, but I never created a static-site-generator. 第二个原因是，我以前从未做过这个。我做过我的web开发的分享，但我从未创建过静态站点生成器。 This made it intriguing because I theoretically had all the prerequisites and skills to build such a tool with my background in web-development, but I had never tried doing it. 这很有趣，因为我在理论上具备了在web开发背景下构建这样一个工具的所有先决条件和技能，但我从未尝试过这样做。 I was hooked, implemented it within about 2 weeks and had a great time doing it. I used my blog-generator for creating this blog and it worked great so far. :) 我被迷住了，在大约两周的时间内实现了它，在实现的时候我很高兴。我用我的博客生成器创建了这个博客，到目前为止效果很好。:) Concept 概念Early on, I decided to write my blog posts in markdown and keep them in a GitHub Repo. The posts are structured in folders, which represent the url of the blog post. 早些时候，我决定使用markdown写我的博客文章，并将他们放在github的仓库（repo）中。文章以文件夹为结构，代表了博客文章的url For metadata, such as publication date, tags, title and subtitle I decided on keeping a meta.yml file with each post.md file with the following format: 至于metadata，例如发布日期，标签，标题和副标题，我决定使用meta.yml，每个帖子都有以下的格式： 12345678title: Playing Around with BoltDB short: &quot;Looking for a simple key/value store for your Go applications? Look no further!&quot;date: 20.04.2017tags: - golang - go - boltdb - bolt This allowed me to separate the content from the metadata, but still keep everything in the same place, where I’d find it later. 这允许我将内容从metadata中分离，但是需要将所有东西放在同一个地方，让我能待会儿能找到它。 The GitHub Repo was my data source. The next step was to think about features and I came up with this List: github repo是我的数据来源。下一步是考虑特性，我想到了以下内容： Very Lean (landing page should be 1 Request &lt; 10K gzipped)非常轻量。（登录页面应该1个请求小于10k） Listing for the landing page and an Archive 展示 Possibility to use syntax-highlighted Code and Images within Blog Posts 在文章中能够使用语法高亮代码，图片 Tags 标签 RSS feed (index.xml) RSS订阅 Optional Static Pages (e.g. About) 可选的静态页面（例如：About） High Maintainability - use the least amount of templates possible 高可维护性-使尽可能少的模板 sitemap.xml for SEO 用于SEO的sitemap.xml Local preview of the whole blog (a simple run.sh script)本地的整个博客的预览(简单的run.sh脚本) Quite a healthy feature set. What was very important for me from the start, was to keep everything simple, fast and clean - without any third-party trackers or ads, which compromise privacy and slow everything down. 相当健壮的特性集.对我来说最开始最重要的，是保持所有的东西都要简单，快速和干净 – 没有任何第三方的跟踪器和广告，保证隐私和使所有事情都放缓。 Based on these ideas, I started making a rough plan of the architecture and started coding. 基于这些想法，我开始对架构进行粗略的规划，并开始编写代码。 Architectural Overview 架构概述The application is simple enough. The high-level elements are: 程序足够简单。高等级的元素如下： CLI 命令行界面 DataSource 数据源 Generators 生成器 The CLI in this case is very simple, as I didn’t add any features in terms of configurability. It basically just fetches data from the DataSource and runs the Generators on it. 在这里CLI非常简单，因为我没有在可配置性方面添加任何特性。仅仅是从DataSource中获取数据 ，并使用生成器运行它。 The DataSource interface looks like this: DotaSource接口长这样： 123type DataSource interface &#123; Fetch(from, to string) ([]string, error)&#125; The Generator interface looks like this:生成器接口长这样： 123type Generator interface &#123; Generate() error&#125; Pretty simple. Each Generator also receives a configuration struct, which contains all the necessary data for generation. 相当简单。每一个生成器都接受一个配置的结构体，包含了所有需要的信息。 There are 7 Generators at the time of writing this post: 写这篇文章的时候，有了7个生成器。 SiteGenerator ListingGenerator PostGenerator RSSGenerator SitemapGenerator StaticsGenerator TagsGeneratorWhere the SiteGenerator is the meta-generator, which calls all other generators and outputs the whole static website. SiteGenerator是meta-generator调用其他所有的生成器并输出整个静态网站的地方。 The generation is based on HTML templates using Go’s html/template package. 生成器基于HTML模板，使用Go的html/template package. Implementation Details 实现细节In this section I will just cover a few selected parts I think might be interesting, such as the git DataSource and the different Generators. 在本节中，我将介绍一些我认为可能很有趣的部分，如git数据源和不同的生成器。 DataSourceFirst up, we need some data to generate our blog from. This data, as mentioned above has the form of a git repository. The following Fetch function captures most of what the DataSource implementation does: 首先，我们需要一些数据来生成我们的博客。如上所述，这些数据具有git存储库的形式。下面的Fetch函数展示了大多数数据源实现的功能: 123456789101112131415161718func (ds *GitDataSource) Fetch(from, to string) ([]string, error) &#123; fmt.Printf("Fetching data from %s into %s...\n", from, to) if err := createFolderIfNotExist(to); err != nil &#123; return nil, err &#125; if err := clearFolder(to); err != nil &#123; return nil, err &#125; if err := cloneRepo(to, from); err != nil &#123; return nil, err &#125; dirs, err := getContentFolders(to) if err != nil &#123; return nil, err &#125; fmt.Print("Fetching complete.\n") return dirs, nil&#125; Fetch is called with two parameters from, which is a repository URL and to, which is the destination folder. The function creates and clears the destination folder, clones the repository using os/exec plus a git command and finally reads the folder, returning a list of paths for all the files within the repository. Fetch使用2个参数来调用，一个是repo的url ，一个是目标的文件夹。这个函数创建并清除目标文件夹，使用os/exec添加一个git命令克隆repo，最后读取文件夹，返回repo中的所有文件的路径列表 As mentioned above, the repository contains only folders, which represent the different blog posts. The array with these folder paths is then passed to the generators, which can then do their thing for each of the blog posts within the repository. 如上所说，这个repo仅仅包含文件夹，代表着不同博客的文章。将这些文件夹路径的数据传递给生成器， Kicking it all off 开始完成所有的目标After the Fetch comes the Generate phase. When the blog-generator is executed, the following code is executed on the highest level: 在Fetch之后，接下来是Generate阶段。当blog-generator执行的时候，下面的代码会最先执行。 12345678910111213ds := datasource.New()dirs, err := ds.Fetch(RepoURL, TmpFolder)if err != nil &#123; log.Fatal(err)&#125;g := generator.New(&amp;generator.SiteConfig&#123; Sources: dirs, Destination: DestFolder,&#125;)err = g.Generate()if err != nil &#123; log.Fatal(err)&#125; The generator.New function creates a new SiteGenerator which is basically a generator, which calls other generators. It’s passed a destination folder and the directories for the blog posts within the repository. generate.New函数创建一个新的SiteGenerate，SiteGenerate是一个基本的生成器，它调用其他生成器。需要传递目标文件夹和生成在repo中博客文章的目录。 As every Generator implementing the interface mentioned above, the SiteGenerator has a Generate method, which returns an error. The Generate method of the SiteGenerator prepares the destination folder, reads in templates, prepares data structures for the blog posts, registers the other generators and concurrently runs them. 正如上面提到的每一个生成器接口的实现，SiteGenerate有一个返回error的Generate方法。SiteGenerate的Generate的方法准备了目标文件夹，读取模板，准备博客文章的数据结构，注册其他生成器并且并发执行他们。 The SiteGenerator also registers some settings for the blog like the URL, Language, Date Format etc. These settings are simply global constants, which is certainly not the prettiest solution or the most scalable, but it’s simple and that was the highest goal here. SiteGenerate同样注册了一些文章的设置，例如URL，语言，数据格式等等。这些设置是简单的全局常量，这当然不是最好的解决办法也不是最有扩展性的，但是它很简单，并且在这里，这是我们的最高目标。 PostsThe most important concept on a blog are - surprise, surprise - blog posts! In the context of this blog-generator, they are represented by the following data-structure: 博客最重要的概念就是博客的文章。在这个blog-生成器的上下文中，它们由以下数据结构表示: 1234567type Post struct &#123; Name string HTML []byte Meta *Meta ImagesDir string Images []string&#125; These posts are created by iterating over the folders in the repository, reading the meta.yml file, converting the post.md file to HTML and by adding images, if there are any. 这些文章是通过在存储库中的文件夹中迭代来创建的，读取meta.yml文件，转换post.md文件到HTML，如果有图像的话添加图像。 Quite a bit of work, but once we have the posts represented as a data structure, the generation of posts is quite simple and looks like this: 做了很多工作，但是一旦我们的post被表示为数据结构，文章的生成就很简单了，看起来就像这样: 123456789101112131415161718func (g *PostGenerator) Generate() error &#123; post := g.Config.Post destination := g.Config.Destination t := g.Config.Template staticPath := fmt.Sprintf("%s%s", destination, post.Name) if err := os.Mkdir(staticPath, os.ModePerm); err != nil &#123; return fmt.Errorf("error creating directory at %s: %v", staticPath, err) &#125; if post.ImagesDir != "" &#123; if err := copyImagesDir(post.ImagesDir, staticPath); err != nil &#123; return err &#125; &#125; if err := writeIndexHTML(staticPath, post.Meta.Title, template.HTML(string(post.HTML)), t); err != nil &#123; return err &#125; return nil&#125; First, we create a directory for the post, then we copy the images in there and finally create the post’s index.html file using templating. The PostGenerator also implements syntax-highlighting, which I described in this post. 首先，我们给post创建一个目录，然后复制图片到这里，最后使用模板创建post的index.html。我在本文中说了，PostGenerate实现了语法高亮。 Listing Creation 清单创建When a user comes to the landing page of the blog, she sees the latest posts with information like the reading time of the article and a short description. For this feature and for the archive, I implemented the ListingGenerator, which takes the following config: 当一个用户访问博客登录界面的时候，她会看到最近的文章的信息，例如阅读文章需要的时间和简单的描述。为了这个特性并且为了存档，我们实现了ListingGenerator，使用了如下的配置： 12345type ListingConfig struct &#123; Posts []*Post Template *template.Template Destination, PageTitle string&#125; The Generate method of this generator iterates over the post, assembles their metadata and creates short blocks based on the given template. Then these blocks are appended and written to the index template. 这个生成器的生成方法在post上迭代，组装它们的元数据，并根据给定的模板创建短块。然后将这些块附加到索引模板中。 I liked medium’s feature to approximate the time to read an article, so I implemented my own version of it, based on the assumption that an average human reads about 200 words per minute. Images also count towards the overall reading time with a constant 12 seconds added for each img tag in the post. This will obviously not scale for arbitrary content, but should be a fine approximation for my usual articles: 我喜欢阅读文章的近似时间的媒体特性，所以我实现了自己的版本。假设人类凭借每分钟阅读200个单词。图片同样计入总阅读时间，以每张图12秒计算。这显然不适合任意内容，但很适合我的文章。 12345678910111213func calculateTimeToRead(input string) string &#123; // an average human reads about 200 wpm var secondsPerWord = 60.0 / 200.0 // multiply with the amount of words words := secondsPerWord * float64(len(strings.Split(input, " "))) // add 12 seconds for each image images := 12.0 * strings.Count(input, "&lt;img") result := (words + float64(images)) / 60.0 if result &lt; 1.0 &#123; result = 1.0 &#125; return fmt.Sprintf("%.0fm", result)&#125; Tags 标签Next, to have a way to categorize and filter the posts by topic, I opted to implement a simple tagging mechanism. Posts have a list of tags in their meta.yml file. These tags should be listed on a separate Tags Page and upon clicking on a tag, the user is supposed to see a listing of posts with the selected tag. 接下来，为了分类和通过主题过滤文章，我选择实现一个简单的标签机制。文章在meta.yml中有标签列表。这些标签应该在独立的标签页中，根据点击一个标签，用户应该能看到这个标签的文章列表。 First up, we create a map from tag to Post: 首先，我们创建标签到文章的映射表。 1234567891011121314func createTagPostsMap(posts []*Post) map[string][]*Post &#123;result := make(map[string][]*Post) for _, post := range posts &#123; for _, tag := range post.Meta.Tags &#123; key := strings.ToLower(tag) if result[key] == nil &#123; result[key] = []*Post&#123;post&#125; &#125; else &#123; result[key] = append(result[key], post) &#125; &#125; &#125; return result&#125; Then, there are two tasks to implement: 然后，有两个任务要去实现 Tags Page 标签页 List of Posts for a selected Tag 展示选择的标签的文章啊The data structure of a Tag looks like this: 数据结构如下12345type Tag struct &#123; Name string Link string Count int&#125; So, we have the actual tag (Name), the Link to the tag’s listing page and the amount of posts with this tag. These tags are created from the tagPostsMap and then sorted by Count descending: 所以，我们有实际的标签（名），标签列表页的连接和这个标签的文章。这些标签由tagPostMap创建，然后根据数目降序排列。12345tags := []*Tag&#123;&#125;for tag, posts := range tagPostsMap &#123; tags = append(tags, &amp;Tag&#123;Name: tag, Link: getTagLink(tag), Count: len(posts)&#125;)&#125;sort.Sort(ByCountDesc(tags)) The Tags Page basically just consists of this list rendered into the tags/index.html file. 标签页仅仅由渲染到tags/index.html的文件组成 The List of Posts for a selected Tag can be achieved using the ListingGenerator described above. We just need to iterate the tags, create a folder for each tag, select the posts to display and generate a listing for them. 选择的标签的文章列表能被存档，使用上面的ListingGenerator。我们仅仅需要迭代标签，给每一个标签创建文件夹，选择选择文章展示并生成列表 Sitemap &amp; RSSTo improve searchability on the web, it’s a good idea to have a sitemap.xml which can be crawled by bots. Creating such a file is fairly straightforward and can be done using the Go standard library. 为了提高网站的搜索能力，有个好主意是拥有一个sitemap.xml，它能够被bots爬到。创建这样的一个文件相当简单，使用Go的标准库就可以了。 In this tool, however, I opted to use the great etree library, which provides a nice API for creating and reading XML. 但是在这个工具里，我选择使用etree库，它提供创建个读取xml非常好用的API。 The SitemapGenerator uses this config: SitemapGenerator使用这个配置： 12345type SitemapConfig struct &#123; Posts []*Post TagPostsMap map[string][]*Post Destination string&#125; blog-generator takes a basic approach to the sitemap and just generates url and image locations by using the addURL function: blog-generator对站点地图进行了基本的处理，并通过使用addURL函数生成url和图像位置。 12345678910111213func addURL(element *etree.Element, location string, images []string) &#123; url := element.CreateElement("url") loc := url.CreateElement("loc") loc.SetText(fmt.Sprintf("%s/%s/", blogURL, location)) if len(images) &gt; 0 &#123; for _, image := range images &#123; img := url.CreateElement("image:image") imgLoc := img.CreateElement("image:loc") imgLoc.SetText(fmt.Sprintf("%s/%s/images/%s", blogURL, location, image)) &#125; &#125;&#125; After creating the XML document with etree, it’s just saved to a file and stored in the output folder. 使用etree创建xml文件之后，保存并存储文件到文件夹中。 RSS generation works the same way - iterate all posts and create XML entries for each post, then write to index.xml. Rss生成器使用同样的方法生成 - 遍历所有文章并为每个post创建XML条目，然后将其写入index.XML。 Handling StaticsThe last concept I needed were entirely static assets like a favicon.ico or a static page like About. To do this, the tool runs the StaticsGenerator with this config: 我所需要的最后一个概念是完全静态的资源，比如favicon.ico或静态页面例如About。为了做到这一点，该工具使用这个配置来运行StaticsGenerator: 12345type StaticsConfig struct &#123; FileToDestination map[string]string TemplateToFile map[string]string Template *template.Template&#125; The FileToDestination-map represents static files like images or the robots.txt and TemplateToFile is a mapping from templates in the static folder to their designated output path. FileToDestination-map表示像图片或者robot.txt的静态文件，TemplateToFiles是从静态文件夹中的模板到指定的输出路径的映射。 This configuration could look like this in practice: 实际上，配置文件是这样的： 12345678910111213fileToDestination := map[string]string&#123; "static/favicon.ico": fmt.Sprintf("%s/favicon.ico", destination), "static/robots.txt": fmt.Sprintf("%s/robots.txt", destination), "static/about.png": fmt.Sprintf("%s/about.png", destination),&#125;templateToFile := map[string]string&#123; "static/about.html": fmt.Sprintf("%s/about/index.html", destination),&#125;statg := StaticsGenerator&#123;&amp;StaticsConfig&#123;FileToDestination: fileToDestination, TemplateToFile: templateToFile, Template: t,&#125;&#125; The code for generating these statics is not particularly interesting - as you can imagine, the files are just iterated and copied to the given destination. 生成这些静态文件的代码不是很有趣 - 正如你想的那样，仅仅就是遍历文件，并复制到目标地点 Parallel Execution 并行执行For blog-generator to be fast, the generators are all run in parallel. For this purpose, they all follow the Generator interface - this way we can put them all inside a slice and concurrently call Generate for all of them. 为了让blog-generator更快，生成器都并行运行。为了这个目的，他们都遵循着Generator的接口 - 这样我可以将他们放在一个slice中，并发的调用生成器。 The generators all work independently of one another and don’t use any global state mutation, so parallelizing them was a simple exercise of using channels and a sync.WaitGroup like this: 生成器运行都相互独立，且不使用任何全局状态变化，所以并行是一个简单的使用channel和sync.WaitGroup的练习，就像这样： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354func runTasks(posts []*Post, t *template.Template, destination string) error &#123; var wg sync.WaitGroup finished := make(chan bool, 1) errors := make(chan error, 1) pool := make(chan struct&#123;&#125;, 50) generators := []Generator&#123;&#125; for _, post := range posts &#123; pg := PostGenerator&#123;&amp;PostConfig&#123; Post: post, Destination: destination, Template: t, &#125;&#125; generators = append(generators, &amp;pg) &#125; fg := ListingGenerator&#123;&amp;ListingConfig&#123; Posts: posts[:getNumOfPagesOnFrontpage(posts)], Template: t, Destination: destination, PageTitle: "", &#125;&#125; ...create the other generators... generators = append(generators, &amp;fg, &amp;ag, &amp;tg, &amp;sg, &amp;rg, &amp;statg) for _, generator := range generators &#123; wg.Add(1) go func(g Generator) &#123; defer wg.Done() pool &lt;- struct&#123;&#125;&#123;&#125; defer func() &#123; &lt;-pool &#125;() if err := g.Generate(); err != nil &#123; errors &lt;- err &#125; &#125;(generator) &#125; go func() &#123; wg.Wait() close(finished) &#125;() select &#123; case &lt;-finished: return nil case err := &lt;-errors: if err != nil &#123; return err &#125; &#125; return nil&#125; The runTasks function uses a pool of max. 50 goroutines, creates all generators, adds them to a slice and then runs them in parallel. runTasks函数使用最大50协程的协程池，创建所有生成器，将他们添加到slice中，然后并行运行他们 These examples were just a short dive into the basic concepts used to write a static-site generator in Go. 这些例子仅仅初步深入基本概念用于使用Go写一个静态网站生成器 If you’re interested in the full implementation, you can find the code here. 如果你对整个实现感兴趣，你可以在这里找到代码. Conclusion 总结Writing my blog-generator was an absolute blast and a great learning experience. It’s also quite satisfying to use my own hand-crafted tool for creating my blog. 编写我的博客生成器是一种绝对的挑战，也是一种很好的学习体验。使用我自己的手工工具创建我的博客也很令人满意。 To publish my posts to AWS, I also created static-aws-deploy, another Go command-line tool, which I covered in this post. 为了发布我的文章到AWS，我同样创建了static-aws-deploy，额外的Go命令行工具，我在这篇文章中会提到提到 If you want to use the tool yourself, just fork the repo and change the configuration. However, I didn’t put much time into customizability or configurability, as Hugo provides all that and more. 如果你想自己使用这个工具，仅仅fork这个repo，并修改配置就可以了。但是，我没有花太多时间来做可定制化和可配置化，因为Hugo提供的了所有你需要的。 Of course, one should strive not to re-invent the wheel all the time, but sometimes re-inventing a wheel or two can be rewarding and can help you learn quite a bit in the process. :) 当然，一个人应该努力不去重新发明轮子，但是有时候重新发明一两个轮子是值得的，可以帮助你在这个过程中学到很多东西。:) Resources blog-generator on GitHub Hugo etree]]></content>
      <categories>
        <category>Go学习小记</category>
      </categories>
      <tags>
        <tag>静态博客</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[(翻译)取消多个Goroutines]]></title>
    <url>%2F2017%2F06%2F28%2F%E7%BF%BB%E8%AF%91-%E5%8F%96%E6%B6%88%E5%A4%9A%E4%B8%AAGoroutines%2F</url>
    <content type="text"><![CDATA[原文 https://chilts.org/2017/06/12/cancelling-multiple-goroutines Cancelling Multiple Goroutines 取消多协程When Go was first released, there was a way to do some things in concurrency. As time has gone on, various things have changed. The Context package for one thing. :) 在Go刚开始发行的时候，只有一种并发的方法。随着时间流逝，很多事情都发生了变化。Context包就是其中之一。 This article doesn’t go into all of the ways of doing concurrency but will focus on one problem and take you through a few different solutions so you can see how things have evolved. 这篇文章不会探究所有并发的方法，但是会研究一个问题，并带你熟悉一些不同的解决方法，让你了解方法是如何推论出来的。 The ProblemThe problem I’d like to address here is being able to cancel multiple goroutines. There are many blog posts out there (I curate @CuratedGo, please follow) which show how to cancel just one goroutine, but my use-case was slightly more complicated. The rest of this article summarises my progress through getting this to work. 我在这里想提出的问题是取消对协程。有许多blog写了如何取消一个协程，但是我的用例是更加复杂的。下面的文章总结了我实现的过程。 The way we’re going decide when to quit is by listening for a C-c keypress. Of course at that point, we want to make sure we tidy up things nicely at that point. For example, if we’re currently streaming tweets from Twitter, we’d rather we told them we’re finished than just drop the connection. 我们要决定何时退出的方式是监听C-c按键。当然，我们确保我们在这一点上很好地处理事情。例如，如果我们目前正在推送Twitter的推文，我们要告诉他们我们已经完成，而不是放弃了解。 Let’s get started.让我们开始吧 A Main without Tidying up1234567891011121314151617package mainimport ( "fmt" "time")func main() &#123; ticker := time.NewTicker(3 * time.Second) for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tick %s\n", now.UTC().Format("20060102-150405.000000000")) &#125; &#125;&#125; And let’s run it and C-c it.12345$ go run 01/tidy.go tick 20170612-213112.045887655tick 20170612-213115.045986150tick 20170612-213118.045993591^Csignal: interrupt Here you can see we have sent the interrupt signal. Make a mental note of that name. However, we haven’t actually tidied up the timer. There are a few ways we could do it, and the easiest for this program is to defer ticker.Stop() so it gets run at the end of main(). 在这里你可以看到，我们发送了中断信号。在心里记住这个名字。但是我们还没有正确的整理好定时器。有许多方法可以做到，其中最简单的是defer tick.Stop(),他在main()的结尾运行。123456789101112131415161718package mainimport ( "fmt" "time")func main() &#123; ticker := time.NewTicker(3 * time.Second) defer ticker.Stop() for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tick %s\n", now.UTC().Format("20060102-150405.000000000")) &#125; &#125;&#125; There is no discernable difference in the output, however you are being a good citizen. :) 在输出的结果中并没有明显的区别，但是你现在是一个良好市民.:)12345$ go run 02/tidy.go tick 20170612-213456.385205269tick 20170612-213459.385180852tick 20170612-213502.385222563^Csignal: interrupt We said earlier that we want to run multiple goroutines and we want to listen for C-c, so let’s do the C-c first.我们之前说过，我们想运行多协程并且我们想监听C-c，所以我们先完成C-c。 Using the os/signal package, we can tell Go to listen for (you guessed it) OS Signals such as os.Interrupt and os.Kill. Let’s see what that looks like: 使用 os/signal包，我们可以告诉Go监听操作系统的信号，例如os.Interrupt和os.Kill。让我们看一下吧。 1234567891011121314151617181920212223242526package mainimport ( "fmt" "os" "os/signal" "time")func main() &#123; ticker := time.NewTicker(3 * time.Second) defer ticker.Stop() c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt) for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tick %s\n", now.UTC().Format("20060102-150405.000000000")) case &lt;-c: fmt.Println("Received C-c - shutting down") return &#125; &#125;&#125; And when we run it, instead of seeing the default message Go provides when it receives an interrupt signal, we can see our own message:12345$ go run 03/tidy.go tick 20170612-214602.313917282tick 20170612-214605.313950300tick 20170612-214608.313950904^CReceived C-c - shutting down Excellent, so let’s start moving the program closer to what we want - running multiple goroutines and stopping them cleanly 非常好，我们将程序改成更接近我们想要的–运行多协程并干净的结束他们 Signalling a Goroutine to Stop 发送信号让协程停止Even though we only have one task at the moment, we will put it into it’s own goroutine and signal it to stop when we have received the C-c. I’m going to use the first half of a post called “Stopping Goroutines” by the excellent Mat Ryer as the basis for this process. Note when this post was written - 2015 - and be sure we’ll change a few things by the time we’ve finished this article. 尽管我们此刻只有一个任务，但我们我们会将他放在他自己的协程中，并且当他接受到C-c信号的时候停止。 The next example shows the ticker in it’s own goroutine. Notice that instead of keeping the signal receiver in the for select case &lt;-c we’ll just change it to &lt;-c since that’s the only thing we’re going to leave in main(). I will prefix the messages with either main or tick so you can see what’s going on. 下一个例子展示了在它自己单独的协程里的ticker。注意，我们将改用&lt;-c, 而不是将信号接受放在for select case &lt;-c中。因为这是我们唯一放在main()中的语句.我将会在消息中加上main或者tick的前缀，让你看到哪一个正在执行。12345678910111213141516171819202122232425262728293031323334353637383940414243444546package mainimport ( "fmt" "os" "os/signal" "time")func main() &#123; // a channel to tell `tick()` to stop, and one to tell us they've stopped stopChan := make(chan struct&#123;&#125;) stoppedChan := make(chan struct&#123;&#125;) go tick(stopChan, stoppedChan) // listen for C-c c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt) &lt;-c fmt.Println("main: received C-c - shutting down") // tell the goroutine to stop fmt.Println("main: telling goroutines to stop") close(stopChan) // and wait for them to reply back &lt;-stoppedChan fmt.Println("main: goroutine has told us they've finished")&#125;func tick(stop, stopped chan struct&#123;&#125;) &#123; // tell the caller we've stopped defer close(stopped) ticker := time.NewTicker(3 * time.Second) defer ticker.Stop() for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tick: tick %s\n", now.UTC().Format("20060102-150405.000000000")) case &lt;-stop: fmt.Println("tick: caller has told us to stop") return &#125; &#125;&#125; Once you press C-c here, you can see the exchange of messages. 一旦你按下了C-c，你可以看到消息的交换。 12345678$ go run 04/tidy.go tick: tick 20170612-220018.345218301tick: tick 20170612-220021.345202622tick: tick 20170612-220024.345147172^Cmain: received C-c - shutting downmain: telling goroutines to stoptick: caller has told us to stopmain: goroutine has told us they've finished So far so good. It works.到现在为止还挺好。它起作用了。 But I can see one problem on the horizon. When we add another goroutine, we’ll have to create another stopped channel for the second goroutine to tell us when they’ve stopped. (Side-note: I originally also created a new stop chan too, but we can re-use that channel for both goroutines.) 但是我预见了一个问题。当我添加另外一个协程时，我们将为第二个协程创建另外一个stoped channel用于告诉我们协程何时停止。（边注：我原来也创建了一个新的stop channel，但是我们可以重新使用该channel用于这两个goroutine） Let’s see what the extra stopped channel looks like. In this example our second goroutine tock() is very similar to the first, except it tocks every 5s instead of ticks every 3s. 让我们看看额外的stopped channel。在这个例子中，我们的第二个goroutine tock()和第一个非常相似，不同点是第二个是每隔5s而第一个是每隔3s。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071package mainimport ( "fmt" "os" "os/signal" "time")func main() &#123; // a channel to tell `tick()` and `tock()` to stop stopChan := make(chan struct&#123;&#125;) // a channel for `tick()` to tell us they've stopped tickStoppedChan := make(chan struct&#123;&#125;) go tick(stopChan, tickStoppedChan) // a channel for `tock()` to tell us they've stopped tockStoppedChan := make(chan struct&#123;&#125;) go tock(stopChan, tockStoppedChan) // listen for C-c c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt) &lt;-c fmt.Println("main: received C-c - shutting down") // tell the goroutine to stop fmt.Println("main: telling goroutines to stop") close(stopChan) // and wait for them to reply back &lt;-tickStoppedChan &lt;-tockStoppedChan fmt.Println("main: all goroutines have told us they've finished")&#125;func tick(stop, stopped chan struct&#123;&#125;) &#123; // tell the caller we've stopped defer close(stopped) ticker := time.NewTicker(3 * time.Second) defer ticker.Stop() for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tick: tick %s\n", now.UTC().Format("20060102-150405.000000000")) case &lt;-stop: fmt.Println("tick: caller has told us to stop") return &#125; &#125;&#125;func tock(stop, stopped chan struct&#123;&#125;) &#123; // tell the caller we've stopped defer close(stopped) ticker := time.NewTicker(5 * time.Second) defer ticker.Stop() for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tock: tock %s\n", now.UTC().Format("20060102-150405.000000000")) case &lt;-stop: fmt.Println("tock: caller has told us to stop") return &#125; &#125;&#125; It’s starting to look unwieldy. However, let’s take a look at the output for completeness:12345678910$ go run 05/tidy.go tick: tick 20170612-220618.466725240tock: tock 20170612-220620.466789888tick: tick 20170612-220621.466756817tick: tick 20170612-220624.466762771^Cmain: received C-c - shutting downmain: telling goroutines to stoptock: caller has told us to stoptick: caller has told us to stopmain: all goroutines have told us they've finished Even though it’s looking a bit nasty, it still works as it should. sync.WaitGroupLet’s try and tidy-up and simplify a bit here. The reason to do this is because if we’d like to add another goroutine to this program - or indeed another 10, 20 or a hundred - we’re going to have a headache with all the channels we need to create. 让我们尝试、整理并简化。做这个的理由是因为如果我们想在这个程序中添加其他goroutine - 或者甚至其他10，20，或者100个 - 处理所有我们需要创建的channel会让我们头疼。 So instead of channels, let’s try another concurrency fundamental that Go provides, which is sync.WaitGroup. Here we create just one WaitGroup (instead of two channels) and use that for the goroutines to signal they’ve finished. Remember, once we create the WaitGroup we shouldn’t copy it, so we need to pass it by reference. 所以，除了channel，让我们尝试另外的Go提供的并发基本原则–sync.WaitGroup.在这里，我们仅仅创建一个WaitGroup(而不是两个channel)，用于当协程结束时发送信息。记住，一旦我们创建了WaitGroup，我们不能拷贝它，我们需要通过引用(指针？？？)传递。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374package mainimport ( "fmt" "os" "os/signal" "sync" "time")func main() &#123; // a channel to tell `tick()` and `tock()` to stop stopChan := make(chan struct&#123;&#125;) // a WaitGroup for the goroutines to tell us they've stopped wg := sync.WaitGroup&#123;&#125; // a channel for `tick()` to tell us they've stopped wg.Add(1) go tick(stopChan, &amp;wg) // a channel for `tock()` to tell us they've stopped wg.Add(1) go tock(stopChan, &amp;wg) // listen for C-c c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt) &lt;-c fmt.Println("main: received C-c - shutting down") // tell the goroutine to stop fmt.Println("main: telling goroutines to stop") close(stopChan) // and wait for them both to reply back wg.Wait() fmt.Println("main: all goroutines have told us they've finished")&#125;func tick(stop chan struct&#123;&#125;, wg *sync.WaitGroup) &#123; // tell the caller we've stopped defer wg.Done() ticker := time.NewTicker(3 * time.Second) defer ticker.Stop() for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tick: tick %s\n", now.UTC().Format("20060102-150405.000000000")) case &lt;-stop: fmt.Println("tick: caller has told us to stop") return &#125; &#125;&#125;func tock(stop chan struct&#123;&#125;, wg *sync.WaitGroup) &#123; // tell the caller we've stopped defer wg.Done() ticker := time.NewTicker(5 * time.Second) defer ticker.Stop() for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tock: tock %s\n", now.UTC().Format("20060102-150405.000000000")) case &lt;-stop: fmt.Println("tock: caller has told us to stop") return &#125; &#125;&#125; The output is exactly the same as the previous program, so we should be on the right lines. The program itself has a few lines removed, a few lines added and looks very similar, however adding new goroutines is a little simpler now. We just need call wg.Add(1) and pass both the stop channel and the waitgroup to it. As I said, it’s only a little simpler but that’s good, right? 输出完全和之前程序一样，所以我们应该在正确的行上。这个程序本身有些行删除了，一些行添加了，看起来差不多，但是添加新的goroutine比之前简单了。我们仅仅需要调用wg.Add(1)，传递stop通道和waitgroup给它。正如我所说的，仅仅简单一点点，但是很不错，对吧？！ 12345678910$ go run 06/tidy.go tick: tick 20170612-221717.992723221tock: tock 20170612-221719.992700713tick: tick 20170612-221720.992722592tick: tick 20170612-221723.992745407^Cmain: received C-c - shutting downmain: telling goroutines to stoptock: caller has told us to stoptick: caller has told us to stopmain: all goroutines have told us they've finished So far, so good. However, there is another problem on the horizon. Let’s imagine we want to also create a webserver in a goroutine. In the past we used to create one using the following code. The problem here though is that the server blocks the goroutine until it has finished. 到现在为止，都很好，但是，又有一个新的问题。让我们想象一下我们也想在goroutine中创建web服务器。过去我们常常使用以下的代码创建协程。而现在的问题是server直到它结束前，一直阻塞着协程。 12345678910111213package mainimport ( "fmt" "net/http")func main() &#123; http.HandleFunc("/", func(w http.ResponseWriter, r *http.Request) &#123; fmt.Fprintln(w, "Hello, World!") &#125;) http.ListenAndServe(":8080", nil)&#125; So the question is, how do we also tell the web server to stop?所以问题是，我们应该怎样告诉web服务器去停止运行。 ContextIn Go v1.7, the context package was added and that is our next secret. The ability to tell a webserver to stop using a context was also added. Using a Context has become the swiss-army knife of concurrency control in Go over the past few years (it used to live at https://godoc.org/golang.org/x/net/context but was moved into the standard library). 在Go的1.7版本加入了context包，这就是我们下一个秘密武器。使用context来停止webservver的运行的能力同样也具有。在Go的过去的几年中，使用Context变成并发控制的瑞士军刀。（它以前在 https://godoc.org/golang.org/x/net/context,但是现在已经移入标准库了） Let’s have a very quick look at how we can create and cancel a Context:让我们快速地了解一下如何创建和取消上下文: 123456789// create a context that we can cancelctx, cancel := context.WithCancel(context.Background())defer cancel()// pass this ctx to our goroutines - each of which would select on `&lt;-ctx.Done()`go tick(ctx, ...)// sometime later ... in our case after a `C-c`cancel() (Side note: if you haven’t see JustForFunc by Francesc Campoy yet, you should watch it - Francesc talks about the Context package in episodes 9 and 10.) One major advantage of using a Context over a stop channel is if any of the goroutines are also creating other goroutines to do the work for them. In the case of using stopped channels we’d have to create more stop channels to tell the child goroutines to finish. We’d also have to tie much of this together to make it work. When we use a Context however, each goroutine would derive a Context from the one it was given, and each of them would be told to cancel. 使用Context比使用stop channel最主要的优势是，协程是否也创建其他协程来工作。因为使用stopped channels，我们不得不创建更多的stop channe，来让子协程终止。我们同样不得不将这些整合起来来让它起作用。但是当我们使用Context，每一个协程都会继承传递给它的Context，并且每一个(继承者)都被告之要删除。 Before we try adding a webserver, let’s change our example above to use a Context. The first thing we’ll need to do is pass the context to each goroutine instead of the channel. Instead of selecting on the channel, it’ll select on &lt;-ctx.Done() and still signal back to main() when it has tidied up. 在我们尝试添加一个webserver之前,让我们修改我们上面使用Context例子。我要做的第一个事情就是将传递channel改为传递Context给每一个goroutine，将监听channel改为监听ctx.Done()，并且仍发送信号，当整理（tidy up）好协程之后返回main() 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677package mainimport ( "context" "fmt" "os" "os/signal" "sync" "time")func main() &#123; // create a context that we can cancel ctx, cancel := context.WithCancel(context.Background()) defer cancel() // a WaitGroup for the goroutines to tell us they've stopped wg := sync.WaitGroup&#123;&#125; // a channel for `tick()` to tell us they've stopped wg.Add(1) go tick(ctx, &amp;wg) // a channel for `tock()` to tell us they've stopped wg.Add(1) go tock(ctx, &amp;wg) // listen for C-c c := make(chan os.Signal, 1) signal.Notify(c, os.Interrupt) &lt;-c fmt.Println("main: received C-c - shutting down") // tell the goroutines to stop fmt.Println("main: telling goroutines to stop") cancel() // and wait for them both to reply back wg.Wait() fmt.Println("main: all goroutines have told us they've finished")&#125;func tick(ctx context.Context, wg *sync.WaitGroup) &#123; // tell the caller we've stopped defer wg.Done() ticker := time.NewTicker(3 * time.Second) defer ticker.Stop() for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tick: tick %s\n", now.UTC().Format("20060102-150405.000000000")) case &lt;-ctx.Done(): fmt.Println("tick: caller has told us to stop") return &#125; &#125;&#125;func tock(ctx context.Context, wg *sync.WaitGroup) &#123; // tell the caller we've stopped defer wg.Done() ticker := time.NewTicker(5 * time.Second) defer ticker.Stop() for &#123; select &#123; case now := &lt;-ticker.C: fmt.Printf("tock: tock %s\n", now.UTC().Format("20060102-150405.000000000")) case &lt;-ctx.Done(): fmt.Println("tock: caller has told us to stop") return &#125; &#125;&#125; There is very little difference between this program and the previous one, however we now have the ability to: 这个程序与之前的有点不一样，我们现在有能力来： create a webserver that we can cancel with the Context创建一个能使用Context取消的webserver pass the same context to sub goroutines which will also cancel their work when toldAnd again, the output is the same. We must be doing something right. 传递相同的context到子协程，并取消协程。输出结果又一次相同。我们做对了。12345678910$ go run 07/tidy.go tick: tick 20170612-223954.341894561tock: tock 20170612-223956.341886006tick: tick 20170612-223957.341887182tick: tick 20170612-224000.341927373^Cmain: received C-c - shutting downmain: telling goroutines to stoptock: caller has told us to stoptick: caller has told us to stopmain: all goroutines have told us they've finished Now let’s get onto the beast and tell our program to also serve HTTP requests. 现在要实现我们的野望了。让我们的程序同样提供HTTP请求 The WebserverBefore we show the entire program, let’s take a look at what the webserver goroutine would look like. The magic here is that instead of calling http.ListenAndServe() we explicitly create the webserver and by doing this we can eventually signal to it to stop. We’re going to model this on the excellent HTTP server connection draining section of this article by Tyler Christensen. 在我们展示全部程序之前，让我们看一下webserver的协程是什么样的。这里神奇的地方是，不是调用 http.ListenAndServe()而是明确的创建webserver并且通过这样做，我们能最终使用信号终止它。我们将要在这优秀的HTTP服务连接上构建这个方法 1234567891011121314151617181920212223242526272829303132333435func server(ctx context.Context, wg *sync.WaitGroup) &#123; // tell the caller that we've stopped defer wg.Done() // create a new mux and handler mux := http.NewServeMux() mux.Handle("/", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; fmt.Println("server: received request") time.Sleep(3 * time.Second) io.WriteString(w, "Finished!\n") fmt.Println("server: request finished") &#125;)) // create a server srv := &amp;http.Server&#123;Addr: ":8080", Handler: mux&#125; go func() &#123; // service connections if err := srv.ListenAndServe(); err != nil &#123; fmt.Printf("Listen : %s\n", err) &#125; &#125;() &lt;-ctx.Done() fmt.Println("server: caller has told us to stop") // shut down gracefully, but wait no longer than 5 seconds before halting shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second) defer cancel() // ignore error since it will be "Err shutting down server : context canceled" srv.Shutdown(shutdownCtx) fmt.Println("server gracefully stopped")&#125; For this func, the only two lines we added in main() were: 对于这个函数来说，只需main()添加两行就行了。 123// run `server` in it's own goroutinewg.Add(1)go server(ctx, &amp;wg) For the output of this program, I will send a request to the server curl localhost:8080 after the first tick and you should see the request start and finish either side of the 2nd tick. And as usual we’ll just show three ticks (and one tock): 输出程序的结果，我将在第一个tick后面向服务器发送请求，你应该看到请求在开始和结束在第二个tick的两边。和通常的一样，我们仅展示3个tick（和一个tock） 1234567891011121314$ go run 08/tidy.go tick: tick 20170612-230003.228960866server: received requesttock: tock 20170612-230005.228893119tick: tick 20170612-230006.228868513server: request finishedtick: tick 20170612-230009.228863351^Cmain: received C-c - shutting downmain: telling goroutines to stopserver: caller has told us to stoptick: caller has told us to stopserver gracefully stoppedtock: caller has told us to stopmain: all goroutines have told us they've finished And as we expected the server also shut down correctly. This time though, I’ll send a request after the 2nd tick but C-c the server before the 3rd tick to demonstrate the server graefully shutting down. 和我们预期的一样，正确的退出了。这一次，我们在第二个tick后发出请求，但是在第三个tick前发送C-c，以此来证明服务器安全退出了。 1234567891011121314$ go run 08/tidy.go tick: tick 20170612-230408.026717601tock: tock 20170612-230410.026710464tick: tick 20170612-230411.026700385server: received request^Cmain: received C-c - shutting downmain: telling goroutines to stoptick: caller has told us to stoptock: caller has told us to stopserver: caller has told us to stopListen : http: Server closedserver: request finishedserver gracefully stoppedmain: all goroutines have told us they've finished Notice that both tick() and tock() finished first, then we had a couple of seconds where we waited for the webserver to finish it’s request and then finally shut down. In the previous example the server shut down when it wasn’t servicing any requests and the srv.ListenAndServe() didn’t return any error. In this example the server was servicing a request and returned the http: Server closed error which appeared above - after which the request finished message appeared to prove the request was still in progress. However, it did finish, the client received the response and everything shut down as expected.、 注意：tick()和tock()先结束，然后我们我们等待了一会服务器完成请求之后，最终退出了。之前的例子，当服务器没有处理任何请求的时候，且 the srv.ListenAndServe()没有返回任何错误，服务器（立即）退出。在这个例子中，服务器处理请求并返回了上面出现的http: Server closed错误 – 请求完成之后，出现的“request finished”信息证明了请求仍然在执行。但是，它的确结束了，客户端收到了响应，一切都像期望的那样结束。 12$ curl localhost:8080Finished! And that’s it! I hope you’ve enjoyed following along in this rather long article, but I hope we demonstrated not just how to use a Context to cancel multiple goroutines, but also how the way we write concurrent Go programs has changed over the years. As with everything, there are many ways to do all of this and I’m sure I’ve missed some but I hope that has given you a taster to play with more concurrency and Context. 我的读（翻译？）后感使用stopped channel等待所有的协程结束123for i := 0; i &lt; count; i++&#123; &lt;-stoppedChan&#125; 来等待所有的协程结束。具体的代码如下1234567891011121314151617181920212223242526// a channel to tell `tick()` and `tock()` to stopstopChan := make(chan struct&#123;&#125;)stoppedChan := make(chan struct&#123;&#125;)count := 0count++go tick(stopChan, stoppedChan)count++go tock(stopChan, stoppedChan)// listen for C-cc := make(chan os.Signal, 1)signal.Notify(c, os.Interrupt)&lt;-cfmt.Println("main: received C-c - shutting down")// tell the goroutine to stopfmt.Println("main: telling goroutines to stop")close(stopChan)// and wait for them both to reply backfor i := 0; i &lt; count; i++&#123; &lt;-stoppedChan&#125; fmt.Println("main: all goroutines have told us they've finished") 确定很明显，子协程仍需要像父线程一样，创建stop channel，麻烦不止一点点。。 我的翻译真是一坨屎。。。。 context.Backgroud()是一个非nil空Context。没有值，没有deadline。经常用于main函数初始化，测试，作为请求的最高等级的Context。 server中的shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)的第一个返回值就是新的带时间截止控制的context。第二个返回值是执行时间到达的时，执行的函数。例如这样：1234shutdownCtx, cancel := context.WithTimeout(context.Background(), 5*time.Second)cancel = func() &#123; fmt.Println("斩斩斩")&#125; 主动创建服务器的过程12345678910111213141516mux := http.NewServeMux()mux.Handle("/", http.HandlerFunc(func(w http.ResponseWriter, r *http.Request) &#123; fmt.Println("server: received request") time.Sleep(3 * time.Second) io.WriteString(w, "Finished!\n") fmt.Println("server: request finished")&#125;))srv := &amp;http.Server&#123;Addr: ":8080", Handler: mux&#125; go func() &#123; // service connections if err := srv.ListenAndServe(); err != nil &#123; fmt.Printf("Listen : %s\n", err) &#125;&#125;() 服务器关闭1srv.Shutdown(shutdownCtx) 注意，此Shutdown方法，只有go的版本大于等于1.8的才有。]]></content>
      <categories>
        <category>Go学习小记</category>
      </categories>
      <tags>
        <tag>Goroutine</tag>
        <tag>channel</tag>
        <tag>context</tag>
        <tag>并发控制</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[lec01学习笔记]]></title>
    <url>%2F2017%2F06%2F28%2Flec01%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[分为: 存储，通讯和计算关键点：实现，性能，容错和一致性。一致性和性能不可兼得split-brain的意思是A true split brain means multiple systems are online and have accessed an exclusive resource simultaneously MapReduce： 定义Map和Reduce函数，输入数组形式的数据。 扩展：不互相等待，不共享数据。可并发执行。可单纯的配置更多的计算机来获得更多的吞吐量性能：Hard to build a network than can run 1000x faster than a single computer.So they cared about minimizing movement of data over the network.一般会被网络限制。尽量减少数据在网络上传输。容错：当Map和Reduce失败时，重新运行。他们仅仅是函数而已–他们不修改输入的内容，不用保存状态，不共享内存，没有Map-Map和Reduce-Reduce的交互。所以重新执行会得到相同的输出。纯函数（pure function）的这个需求是相对于其他并行编程方案的主要限制，也是MR简单的原因。 MapReduce由Mater和Worker组成。Master给workers分配工作，决定worker运行map方法还是reduce方法。当worker执行错误，直接重启worker就好。master的调度程序123456789101112131415161718192021222324252627282930313233343536373839func (mr *Master) schedule(phase jobPhase) &#123; var ntasks int var nios int // number of inputs (for reduce) or outputs (for map) switch phase &#123; case mapPhase: ntasks = len(mr.files) nios = mr.nReduce case reducePhase: ntasks = mr.nReduce nios = len(mr.files) &#125; fmt.Printf("Schedule: %v %v tasks (%d I/Os)\n", ntasks, phase, nios) var wg sync.WaitGroup for i := 0; i &lt; ntasks; &#123; wg.Add(1) go func(i, nios int, phase jobPhase) &#123; defer wg.Done() workrName := &lt;-mr.registerChannel for true &#123; ok := call(workrName, "Worker.DoTask", &amp;DoTaskArgs&#123; JobName: mr.jobName, File: mr.files[i], Phase: phase, TaskNumber: i, NumOtherPhase: nios, &#125;, new(struct&#123;&#125;)) if ok &#123; go func() &#123; mr.registerChannel &lt;- workrName &#125;() return &#125; &#125; &#125;(i, nios, phase) &#125; wg.Wait() fmt.Printf("Schedule: %v phase done\n", phase)&#125; map方法读入input数据，使用mapF将数据处理之后，将处理后的数据存在指定的中间文件中，中间文件的文件名决定此文件将由哪个reduce执行。 123456789101112131415161718192021222324252627func doMap( jobName string, // the name of the MapReduce job mapTaskNumber int, // which map task this is inFile string, nReduce int, // the number of reduce task that will be run ("R" in the paper) mapF func(file string, contents string) []KeyValue,) &#123; content, err := ioutil.ReadFile(inFile) if err != nil &#123; log.Fatal("read input file content ", err) &#125; kvs := mapF(inFile, string(content)) files := []*os.File&#123;&#125; for i := 0; i &lt; nReduce; i++ &#123; fileName := reduceName(jobName, mapTaskNumber, i) file, err := os.Create(fileName) if err != nil &#123; log.Fatal("Create File", err) &#125; defer file.Close() files = append(files, file) &#125; for _, kv := range kvs &#123; e := json.NewEncoder(files[int(ihash(kv.Key))%nReduce]) e.Encode(&amp;kv) &#125;&#125; reduce读取指定的中间文件，使用reduceF处理后，输出结果。 12345678910111213141516171819202122232425262728293031323334353637383940414243func doReduce( jobName string, // the name of the whole MapReduce job reduceTaskNumber int, // which reduce task this is nMap int, // the number of map tasks that were run ("M" in the paper) reduceF func(key string, values []string) string,) &#123; kvMap := make(map[string][]string) // 读取同一个 reduce task 下的所有文件，保存至哈希表 for i := 0; i &lt; nMap; i++ &#123; filename := reduceName(jobName, i, reduceTaskNumber) f, err := os.Open(filename) if err != nil &#123; log.Fatal("Open File Err: ", filename) &#125; defer f.Close() decoder := json.NewDecoder(f) var kv KeyValue for decoder.More() &#123; err := decoder.Decode(&amp;kv) if err != nil &#123; log.Fatal("Json decode failed, ", err) &#125; kvMap[kv.Key] = append(kvMap[kv.Key], kv.Value) &#125; &#125; // 对哈希表所有 key 进行升序排序 keys := []string&#123;&#125; for k, _ := range kvMap &#123; keys = append(keys, k) &#125; sort.Strings(keys) mergeFile, err := os.Create(mergeName(jobName, reduceTaskNumber)) if err != nil &#123; log.Fatal("Create Merge File Err: ", err) &#125; defer mergeFile.Close() encoder := json.NewEncoder(mergeFile) for _, k := range keys &#123; encoder.Encode(KeyValue&#123;k, reduceF(k, kvMap[k])&#125;) &#125;&#125; (课程),[https://github.com/qwendy/Distributed-Systems/tree/master/Lec01_Introduction](实验的代码)[https://github.com/qwendy/Distributed-Systems/tree/master/6.824/src/mapreduce]]]></content>
      <categories>
        <category>6.824课程</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>MapReduce</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[使用网页打开本地程序]]></title>
    <url>%2F2017%2F06%2F21%2F%E4%BD%BF%E7%94%A8%E7%BD%91%E9%A1%B5%E6%89%93%E5%BC%80%E6%9C%AC%E5%9C%B0%E7%A8%8B%E5%BA%8F%2F</url>
    <content type="text"><![CDATA[浏览器中使用 window.open()打开 URL。当 URL 为特定的前缀的时候（URI Scheme），就会调用注册表中对应的指令。 写入注册表参考 https://msdn.microsoft.com/en-us/library/aa767914(VS.85).aspx其中的关键是在注册表中写入如下的注册表项 12345678910HKEY_CLASSES_ROOT alert (Default) = &quot;URL:Alert Protocol&quot; URL Protocol = &quot;&quot; DefaultIcon (Default) = &quot;alert.exe,1&quot; shell open command (Default) = &quot;C:\Program Files\Alert\alert.exe&quot; &quot;%1 使用 go 操作注册表.path 为程序的地址。uri 为调用程序的 URI Scheme。使用 js 调用 window.open(“uri://“)就可以打开程序。 12345678910111213141516171819202122232425262728293031func regKey(path string,uri string) error &#123; vconsoleKey, ok, err := registry.CreateKey(registry.CLASSES_ROOT, uri, registry.CREATE_SUB_KEY|registry.SET_VALUE) if err != nil &#123; logger.Printf("CreateKey console err :%v\n", err) return err &#125; if ok &#123; return err &#125; defer vconsoleKey.Close() vconsoleKey.SetStringValue("URL Protocol", "") vconsoleKey.SetStringValue("DefaultIcon", path) shellKey, _, err := registry.CreateKey(vconsoleKey, `shell`, registry.CREATE_SUB_KEY) if err != nil &#123; logger.Printf("CreateKey shell err :%v\n", err) return err &#125; openKey, _, err := registry.CreateKey(shellKey, `open`, registry.CREATE_SUB_KEY) if err != nil &#123; logger.Printf("CreateKey open err :%v\n", err) return err &#125; commandKey, _, err := registry.CreateKey(openKey, `command`, registry.CREATE_SUB_KEY|registry.SET_VALUE) if err != nil &#123; logger.Printf("CreateKey err :%v\n", err) return err &#125; commandKey.SetStringValue("", path) return nil&#125; 获取管理员权限在注册表中写入注册表项需要管理员权限。 go get github.com/akavel/rsrc 把 nac.manifest 文件拷贝到当前 windows 项目根目录 rsrc -manifest nac.manifest -o nac.syso go build nac.mainfest 的内容为： 12345678910&lt;?xml version="1.0" encoding="UTF-8" standalone="yes"?&gt;&lt;assembly xmlns="urn:schemas-microsoft-com:asm.v1" manifestVersion="1.0"&gt;&lt;trustInfo xmlns="urn:schemas-microsoft-com:asm.v3"&gt;&lt;security&gt;&lt;requestedPrivileges&gt;&lt;requestedExecutionLevel level="requireAdministrator"/&gt;&lt;/requestedPrivileges&gt;&lt;/security&gt;&lt;/trustInfo&gt;&lt;/assembly&gt;]]></content>
      <categories>
        <category>杂记</category>
      </categories>
      <tags>
        <tag>go</tag>
        <tag>注册表</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（翻译）BitTorrent-Protocol协议规范]]></title>
    <url>%2F2016%2F12%2F26%2F%EF%BC%88%E7%BF%BB%E8%AF%91%EF%BC%89BitTorrent-Protocol%E5%8D%8F%E8%AE%AE%E8%A7%84%E8%8C%83%2F</url>
    <content type="text"><![CDATA[本文翻译原文：http://www.bittorrent.org/beps/bep_0003.htmlBitTorrent是一个分发文件的协议。它通过URL识别内容，旨在与网络无缝集成。它和一般的HTTP相比的优势在于，当同一个文件的多个下载同时发生时，下载者相互上传，使得文件源可以支持非常大量下载，而其负载增加很小。 BitTorrent文件分发有这些部分组成： 一个普通的web服务器 静态“元信息（metainfo）”文件 BitTorrent跟踪器（tracker） “原始”下载器 用户web浏览器端 用户下载器端 理想情况下多端用户现在同一个文件 要开始服务，主机将执行以下步骤 开启一个跟踪器（tracker） 开启一个普通的web服务器，例如Apache 在他们的Web服务器上，将扩展名.torrent与mimetype应用程序/ x-bittorrent相关联。 使用提供的完整的文件和跟踪器URL，生成一个元数据（metainfo）的(.torrent) 文件 将元信息(.torrent)文件放在web服务器上 链接来自其它网页的(.torrent)元数据文件 bencoding 十进制的字符串长度，后面跟着冒号和字符串。例如4:spam对应于“span” 整数用一个’i’来表示，后跟一个十进制的数字，再后面跟着一个’e’。例如：i3e对应3，i-3e代表-3。整数没有大小限制，i-0e是无效的。所有具有前导0的编码，例如i03e，都是无效的，除了i0e，其毫无疑问对应0。 列表被编码成‘l’，后面是他们的元素（也是bencode），在接着是‘e’.例如：l4：spam4：eggs对应：[‘spam’,’eggs’]. 字典被编码成’d’，后面跟着一个交替的建和对应的列表，后跟一个’e’。例如，d3:cow3:moo4:spam4:eggse 对应{‘cow’: ‘moo’, ‘spam’: ‘eggs’}， d4:spaml1:a1:bee对应{‘spam’: [‘a’, ‘b’]}。键必须是字符串并按排序顺序显示（按原始字符串排序，而不是字母数字）。 metainfo files(元信息文件)元信息文件（也被认作.torrent文件）使用以下键编程成bencoded字典： announce： 跟踪器（tracker）的URL info： 映射到字典，具有如下所述的键。 所有在.torrent文件中包含的字符串必须是UTF-8编码的 信息字典映射UTF编码的字符串的关键字，是用来保存文件的默认名字。它仅仅用来咨询。片段（piece）长度对应到文件被分割成的每个片段中的字节数。为了传输的目的，文件被拆分成固定大小的块，它们具有相同的长度，除了可能被截断的最后一个之外。片（piece）长度几乎总是2的幂，最常见的2 18 = 256 K（BitTorrent在版本3.2之前使用2 20 = 1 M作为默认值）。它被细分为长度为20的字符串，每个字符串是相应索引处的片段的SHA1哈希。还有一个密钥长度或一个密钥文件，但不能同时存在或同时不存在。如果长度存在，则下载表示单个文件，否则它表示进入目录结构的一组文件。在单个文件的情况下，长度映射到文件的长度（以字节为单位）。为了其他键的目的，多文件情况被视为只有一个文件，通过按照它们出现在文件列表中的顺序连接文件。文件列表是文件映射到的值，是包含以下键的字典列表： length：文件的长度（以字节为单位）。 path 与子目录名称对应的UTF-8编码字符串的列表，最后一个是实际文件名（零长度列表是一个错误大小写）。在单文件的情况下，名称键是文件的名称，在多文件的情况下，它是目录的名称。 跟踪器（tracker）跟踪器请求包含以下关键字（key）： info_hash 来自metainfo文件的info值的bencoded形式的20字节sha1散列。注意，这是metainfo文件的子字符串。 info_hash必须是在.torrent文件中找到的编码形式的哈希，而不管它是无效的。这个值肯定必须被转义。 peer_id 是长度为20的字符串，被下载程序用作其id。每个下载程序在新下载开始时随机生成自己的ID。这个值也必须被转义。 ip 是此peer所在的IP（或dns名称）的可选参数。 port 是peer正在侦听的端口号。常见的做法是下载器尝试侦听端口6881，如果该端口被占用，则尝试6882，接着6883等，在尝试6889端口后若仍不成功，则放弃. upload 目前为止所有的上传量，编码成十进制ascii码。 downloaded 到目前为止已下载的总量，编码成十进制ascii码。 left peer的剩余下载量，以十进制ascii编码。请注意，这不能从已下载的量和文件长度计算，因为它可能只是一个摘要，并且有可能是，部分已下载的数据的完整性检查失败，必须重新下载。 event 这是一个对应started，completed或stopped 的可选键（或empty，代表不存在）。如果不存在，则定时发出公告。当下载开始时，发送started的通知，并且当下载完成时发送completed。如果文件在启动时已完成，则不会发送completed。下载器在停止下载时发送stopped公告。 跟踪器（Tracker）的响应是经过bencoded编码的字典。如果跟踪器响应具有关键值的失败原因，则对应到人类可读的字符串，解释了为什么查询失败，并且不需要关其他键字（keys）。除此之外，必须有两个关键字：interval，对应下载器在定期重新请求时应该等待多少秒。peers，对应peers相应的字典列表，每一个都包含peer id，ip和port，peer id指的是peer自选ID，ip指的是IP地址或者dns名字，port指的是端口数。注意，如果有事件发生，或者需要更多的peer，下载器可以在未调度的时间重新请求。更常见的是跟踪器返回peer列表的压缩表示，参见BEP 23。通常也通过UDP跟踪器协议来通告。 对等协议（peer protocal）BitTorrent的对等协议通过TCP或uTP进行操作。peer的连接是对称的。在两个方向上发送的消息看起来是相同的，并且数据可以在任一方向上流动。 对等协议指的是，在元信息文件中描述的索引零的文件片段。当peer下载完一个块（piece）并且该散列匹配时，它向其他所有的peer宣告它具有了那个块。连接在任一端都包含两位状态：阻塞（choked）或者非阻塞，感兴趣（interested）或者不感兴趣。阻塞表示在非阻塞发生前，不会有数据发送。文档后面将解释阻塞的推论和通用技术。 只要一方感兴趣，另一方没有阻塞，就进行数据传输。必须随时保持最新感兴趣状态 - 每当下载者当前没有某些资源时，将会向一个peer询问是否处于非阻塞状态，即使被阻塞。他们也必须表示不感兴趣。正确的实现这个很刺手，但是这可以下载者知道，如果不阻塞，哪一个peer将会开始下载。 连接开始，就将状态变为被阻塞和不感兴趣。 当数据被传输时，下载器应该将多个块放在队列中一并请求，以获取更好的TCP性能（这叫做流水线）。另一方面，不能立即写入TCP缓冲器的请求应当在存储器中排队，而不是保留在应用级网络缓冲器中，因此当发生阻塞时，它们都可以被抛弃。 对等线协议由握手和包含长度前缀消息的不间断流组成。握手的开头是字符19（十进位的），然后是字符串BitTorrent protocol。前导字符是一个长度前缀，放在那里，希望其他新协议也这样，可以彼此区分。 在协议中发送的所有后面出现的整数被编码为四字节（大端排序）。在固定的报头之后有八个保留字节，在所有当前实现中它们都为零。如果您希望使用这些字节扩展协议，请与Bram Cohen协调，以确保所有扩展都兼容。 接下来是来自metainfo文件的info值的bencoded形式的20字节sha1散列。（这个和发送给tracker的info_hash是一样的值，只在这里它是原始的，而不是引用）。如果双方都不发送相同的值，它们将断开连接。一个可能出现的情况是如果下载者想通过单个端口进行多次下载，他们会等待传入的连接，并首先给出一个下载哈希，并且如果它在它们的列表中，则用同一个哈希进行响应。 在下载哈希值之后，20个字节的对等体ID在跟踪器请求中报告并且包含在跟踪器响应中的对等体列表中。如果接收方的对等体ID与发起方期望的不匹配，则它切断连接。 这是握手，接下来是一个交替的长度前缀和消息的流。长度为零的消息是保持活动，并被忽略。 Keepalive通常每两分钟发送一次，但请注意，当预期数据时，超时可以更快地完成。]]></content>
      <categories>
        <category>DHT</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>DHT</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[（翻译）Sharding-mongo官方文档3.2版本]]></title>
    <url>%2F2016%2F12%2F22%2F%EF%BC%88%E7%BF%BB%E8%AF%91%EF%BC%89Sharding-mongo%E5%AE%98%E6%96%B9%E6%96%87%E6%A1%A33-2%E7%89%88%E6%9C%AC%2F</url>
    <content type="text"><![CDATA[此篇文章为mongo官方文档，版本为3.2. 地址为：https://docs.mongodb.com/v3.2/core/sharded-cluster-components/ 分片（Sharding）分片是一个在多个主机上分发数据的方法。 MongoDB用分片实现大数据集合和高吞入量操作。大数据量集合和高吞吐量操作应用数据库系统挑战单个服务器的容量。例如，高请求速率能耗尽CPU性能。工作集大小大于系统的RAM给磁盘驱动器的I / O性能施加压力有两种方法处理系统的增长：垂直扩展和水平扩展垂直扩展涉及扩大单个服务器的性能，例如使用更强大的CPU，添加更多RAM，或者增加存储空间。可用技术中的限制可能会限制单个机器的工作负载能力。另外，云服务提供商在可用的硬件配置上设置上限。所以，对于垂直扩展存在实际的最大值。水平扩展涉及将系统的数据集切分并通过多服务器加载，添加另外的服务器来扩大需要的容量。既然单个机器的整体速度和容量不高，那么每个机器处理整个工作量的一部分，可能提供比一个高速度高容量服务器更好的效果。扩展部署的容量仅需要根据需要添加额外的服务器，总体成本可能比单个机器的高端硬件低。MongoDb支持通过分片来进行水平扩展。 分片集群MongoDB的分片集群由以下组件组成： 分片（shard）：每个分片包含被分片数据的子集。每个分片可以被部署成副本集 mongos:mogos扮演查询路由（query router）的角色，提供一个在客户端个分片集群之间的接口 config servers: 配置服务器存储元数据（metadata）并配置集群的设置。在MongoDB 3.4，配置服务器必须部署成副本集 下面这张图描述了在一个分片集群中的交互 MongoDB分片数据是collection级别的，在集群中分发collection数据 Shard keys为了分发collection中的document，MongoDB使用shard key来对collection进行分区。shard key包含存在于目标collection中的每个document中的不可变的一个字段或者多个字段。当分片一个collection的时候选择shard key。分片后不能修改选择的shard key。一个分片collection只有一个shard key。为了分片一个非空的collection，collection必须有一个由shard key开始的索引。对应空的collection，如果collection没有社和的索引来作为特殊的shard key。MongoDB创建一个索引。shard key的选择影响分片集群的性能，效率和课扩展性。拥有最佳的可能的硬件和基础设施的集群可以通过选择shard key来突破瓶颈。选择分片键及其后缀索引还可以影响集群可以使用的分片策略。 块（Chunks）MongoDb将分片的数据分割成块（Chunks）。每一个Chunk都根据shard key包含上限和下限。MongoDB使用分片集群均衡器（sharded cluster balancer）来在分片集群中的shard中迁移块（chunks）。均衡器尝试在集群中的所有分片之间实现块（chunk）的平衡 分片的优势读/写MongoDB分发读写工作负载到分片集群中的分片服务器中（shard），允许每一个shard运行集群操作的子集。读和写工作负载都可以通过增加更多的shard来水平扩展。对于包含shard key或复合shard key的前缀的查询，mongos可以在特定的分片（shard）或分片集上定位查询。这些目标操作通常比向集群中的每个分片广播更有效。 存储容量在集群中的分片服务器（Shard）中分发共享数据，允许每一个shard包含集群中所有数据的子集。随着数据增长，额外的shards扩大了集群的存储容量。 高可用性分片集群可以继续执行部分读/写操作，即使一个或者更多的分片服务器（shards）不能使用。虽然在宕机的时间内无法访问在不可用分片服务器上的数据子集，但针对可用分片的读取或写入仍然可以成功。在生产环境中，应将单个碎片部署为副本集，从而提高冗余和可用性 分片前的注意事项分片式集群基础架构要求和复杂性需要仔细规划，执行和维护。仔细考虑选择shard key对于确保集群性能和效率是必要的。您不能在分片后更改分片键，也不能取消分片集合。如果查询不包括shard key或复合shard key的前缀，则mongos执行广播操作，查询分片群集中的所有分片。这些分散/聚集查询可能导致长时间运行操作。 分片的和未分片的集合数据库可以混合着分片和非分片集合。分片集合被分区并分布在集群中的分片上。未分片集合存储在主分片上。每个数据库都有自己的主分片。 连接分片集群您必须连接到mongos路由器才能与分片集群中的任何集合进行交互。这包括分片和非分片集合。客户端不应该连接到单个分片以执行读取或写入操作。 你可以像连接到mongod一样连接到mongos，例如通过mongo shell或MongoDB驱动程序 分片策略MongoDB支持两种分片策略，用于在分片集群中分发数据。 散列分片（Hashed Sharding）散列分片涉及计算分片键字段值的散列。然后根据散列分片键值为每个块分配一个范围。 虽然分片键的范围“相近”，但是它们的散列值不可能在同一块上。 基于散列值的数据分布有助于更均匀的数据分布，特别是在碎片键单调变化的数据集中然而，散列分布意味着对分片键的基于范围的查询不太可能针对单个分片，导致更多的集群广播操作。 范围分片（Ranged Sharding）远程分片涉及基于shard key将数据划分为范围。然后根据shard key为每个块（chunk）分配一个范围。 其值“相近”的分片键（shard key）的范围更可能驻留在同一块上。这允许目标操作，因为mongos可以将操作路由到只包含所需数据的分片。范围分片的效率取决于所选的分片键。考虑不周的分片键可能导致数据分布不均匀，这可能会抵消分片的一些好处，或者可能导致性能瓶颈。 Tag Aware Sharding（3.4版本为Zones in Sharded Clusters）在分片集群中，您可以标记分片键的特定范围，并将这些标签与分片或分片子集相关联。MongoDB将落入标记范围的读取和写入仅路由到分配了该标记的那些分片。另外，均衡器在均衡时检查标签，确保每一个分片只包含不违反它配置的标签范围的数据。每一个标签都有一个包含上限和下限的范围。管理员可以在集群中每一个分片上（shard）分配一个或者更多的标签 标记范围必须使用来自分片键的字段，并遵守复合分片键字段的顺序。在选择shard key时，请仔细考虑将来使用标记感知分片的可能性，因为在分片collection后无法更改分片键。最常见的是，标记感知分片用于改善跨越多个数据中心的分片簇的数据的局部性。]]></content>
      <categories>
        <category>数据库学习记录</category>
      </categories>
      <tags>
        <tag>mongo</tag>
        <tag>sharding</tag>
        <tag>翻译</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB-Sharding常用命令]]></title>
    <url>%2F2016%2F12%2F22%2FMongoDB-Sharding%E5%B8%B8%E7%94%A8%E5%91%BD%E4%BB%A4%2F</url>
    <content type="text"><![CDATA[资料来源： https://docs.mongodb.com/v3.2/tutorial/administer-shard-tags/详细命令参考： https://docs.mongodb.com/v3.2/reference/sharding/ 分片常用配置Sharding 连接路由服务器 1.\bin\mongo.exe admin --port 40000 设置分片服务器 12345db.runCommand(&#123; addshard:&quot;127.0.0.1:27100&quot; &#125;)db.runCommand(&#123; addshard:&quot;127.0.0.1:27101&quot; &#125;)db.runCommand(&#123; addshard:&quot;127.0.0.1:27017&quot; &#125;)或者sh.addShard(&quot;127.0.0.1:27100&quot;) 设置要分片的数据库 123db.runCommand(&#123; enablesharding:&quot;qdgame&quot; &#125;)或者：sh.enableSharding(&quot;qdgame&quot;) 关闭balancing 1sh.disableBalancing(&quot;qdgame.backpack&quot;) 设置要分片的collection 123db.runCommand(&#123; shardcollection: &quot;qdgame.backpack&quot;, key: &#123; _id:1&#125;&#125;)或者sh.shardCollection(&quot;qdgame.backpack&quot;,&#123;usrid:1, id:1&#125;) 开启balancing 1sh.enableBalancing(&quot;qdgame.backpack&quot;) 注意：设置一定要在admin数据库下。 使用hash分片一个collection1sh.shardCollection( &quot;database.collection&quot;, &#123; &lt;field&gt; : &quot;hashed&quot; &#125; ) 改变chunk大小1db.settings.save( &#123; _id:&quot;chunksize&quot;, value: &lt;size&gt; &#125; ) 添加index索引1db.collection.ensureIndex(&#123;a:1,b:-1&#125;) 管理分片标签标记一个分片当连接到mongos实例时，使用sh.addShardTag（）方法将标记与特定分片关联。单个分片可以具有多个标签，并且多个分片也可以具有相同的标签。1234sh.addShardTag(&quot;shard0000&quot;, &quot;NYC&quot;)sh.addShardTag(&quot;shard0001&quot;, &quot;NYC&quot;)sh.addShardTag(&quot;shard0002&quot;, &quot;SFO&quot;)sh.addShardTag(&quot;shard0002&quot;, &quot;NRT&quot;) 在连接到mongos实例时，您可以使用sh.removeShardTag（）方法从特定分片中删除标签，如以下示例所示，该示例从分片中删除NRT标签：1sh.removeShardTag(&quot;shard0002&quot;, &quot;NRT&quot;) 标记shard key范围在连接到mongos实例时使用sh.addTagRange（）方法来给某个范围的shard key添加标签。任何给定的分片键范围都只具有一个分配的标签。您不能重叠定义的范围，也不能多次标记同一范围。123sh.addTagRange(&quot;records.users&quot;, &#123; zipcode: &quot;10001&quot; &#125;, &#123; zipcode: &quot;10281&quot; &#125;, &quot;NYC&quot;)sh.addTagRange(&quot;records.users&quot;, &#123; zipcode: &quot;11201&quot; &#125;, &#123; zipcode: &quot;11240&quot; &#125;, &quot;NYC&quot;)sh.addTagRange(&quot;records.users&quot;, &#123; zipcode: &quot;94102&quot; &#125;, &#123; zipcode: &quot;94135&quot; &#125;, &quot;SFO&quot;) 从shard key范围中删除标记12use configdb.tags.remove(&#123; _id: &#123; ns: &quot;records.users&quot;, min: &#123; zipcode: &quot;10001&quot; &#125;&#125;, tag: &quot;NYC&quot; &#125;) 访问标签sh.status（）列出与每个分片相关联的分片（如果有的话）的标签。shard的标记存在于config数据库的shards集合中的shard文档中。12use configdb.shards.find(&#123; tags: &quot;NYC&quot; &#125;) 您可以在config数据库的tags集合中找到所有命名空间的标记范围。 sh.status（显示所有标签范围。要返回用NYC标记的所有shard key范围，请使用以下操作：12use configdb.shards.find(&#123; tags: &quot;NYC&quot; &#125;) 例子：根据地区来划分数据场景在messages集合中创建测试数据如下：123456789101112131415161718192021&#123; &quot;_id&quot; : ObjectId(&quot;56f08c447fe58b2e96f595fa&quot;), &quot;country&quot; : &quot;US&quot;, &quot;userid&quot; : 123, &quot;message&quot; : &quot;Hello there&quot;, ...,&#125;&#123; &quot;_id&quot; : ObjectId(&quot;56f08c447fe58b2e96f595fb&quot;), &quot;country&quot; : &quot;UK&quot;, &quot;userid&quot; : 456, &quot;message&quot; : &quot;Good Morning&quot; ...,&#125;&#123; &quot;_id&quot; : ObjectId(&quot;56f08c447fe58b2e96f595fc&quot;), &quot;country&quot; : &quot;DE&quot;, &quot;userid&quot; : 789, &quot;message&quot; : &quot;Guten Tag&quot; ...,&#125; shard keymessages集合使用{ country : 1, userid : 1 }组合索引作为shard key。每个文档中的country 字段允许在每个不同的country值上创建标签范围。相对于country，userid字段为shard key提供一个高基数低频率的元素 写操作在Tag相关的分片中，mongos将到来的文档和配置的tag范围比较。如果文档符合配置标签的范围，mongos将此文档路由到此标签的分片中这插入环节，MongoDB可以将不合格任何tag范围的文档路由到随机的分片中。 读操作如果这个请求至少包含country字段，MongoDB可以路由请求到特定的分片中。例如MongoDB可以尝试对以下查询执行有针对性的读取操作：12chatDB = db.getSiblingDB(&quot;chat&quot;)chatDB.messages.find( &#123; &quot;country&quot; : &quot;UK&quot; , &quot;userid&quot; : &quot;123&quot; &#125; ) 均衡器均衡器迁移带有tag的块（Chunk）到适合的分片（shard）。在迁移之前，分片可能包含违反配置的tag和tag范围的块。一旦平衡完成，碎片应只包含不违反其分配的标记和标记范围的块。添加个删除标签可以块的迁移。这取决于数据集的大小和标记范围影响的块数量，这些迁移可能会影响集群的性能。 操作取消均衡器为了降低性能影响，可以在集合上禁用平衡器，以确保在配置新标记时不会发生迁移。考虑在特定的计划窗口中运行均衡器。1sh.disableBalancing(&quot;chat.message&quot;) 使用sh.isBalancerRunning()来检查平衡器进程当前是否正在运行。等待任何当前平衡回合完成后再继续。 为每一个分片添加标签1sh.addShardTag(&lt;shard name&gt;, &quot;NA&quot;) 您可以通过运行sh.status（）来查看分配给给定分片的标签。 定义标签范围使用sh.addTagRange()方法。这个方法需要： 完成的目标collection的名字 范围的下限 范围的上限 标签的名字 123456sh.addTagRange( &quot;chat.messages&quot;, &#123; &quot;country&quot; : &quot;US&quot;, &quot;userid&quot; : MinKey &#125;, &#123; &quot;country&quot; : &quot;US&quot;, &quot;userid&quot; : MaxKey &#125;, &quot;NA&quot;) 开启均衡器1sh.enableBalancing(&quot;chat.message&quot;) 使用sh.isBalancerRunning()来检查平衡器进程当前是否正在运行 查看更改您可以使用sh.status()]]></content>
      <categories>
        <category>数据库学习记录</category>
      </categories>
      <tags>
        <tag>mongo</tag>
        <tag>sharding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Go语言圣经》学习小记（2）]]></title>
    <url>%2F2016%2F12%2F20%2F%E3%80%8AGo%E8%AF%AD%E8%A8%80%E5%9C%A3%E7%BB%8F%E3%80%8B%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0%EF%BC%882%EF%BC%89%2F</url>
    <content type="text"><![CDATA[函数函数声明在函数体中，函数的形参作为局部变量，被初始化为调用者提供的值。函数的形参和有名返回值作为函数最外层的局部变量，被存储在相同的词法块中。实参通过值的方式传递，因此函数的形参是实参的拷贝。对形参进行修改不会影响实参。但是，如果实参包括引用类型，如指针，slice(切片)、map、function、channel等类型，实参可能会由于函数的简介引用被修改。没有函数体的函数声明，这表示该函数不是以Go实现的。这样的声明定义了函数标识符。12package mathfunc Sin(x float64) float //implemented in assembly language 注：此代码来自官方的math包中 错误在Go中，函数运行失败时会返回错误信息，这些错误信息被认为是一种预期的值而非异常（exception）。 函数值在Go中，函数被看作第一类值（first-class values）：函数像其他值一样，拥有类型，可以被赋值给其他变量，传递给函数，从函数返回。123456789func square(n int) int &#123; return n * n &#125;func negative(n int) int &#123; return -n &#125;func product(m, n int) int &#123; return m * n &#125;f := squarefmt.Println(f(3)) // "9"f = negativefmt.Println(f(3)) // "-3"fmt.Printf("%T\n", f) // "func(int) int"f = product // compile error: can't assign func(int, int) int to func(int) int 函数类型的零值是nil。调用值为nil的函数值会引起panic错误函数值可以与nil比较但是函数值之间是不可比较的，也不能用函数值作为map的key。 匿名函数拥有函数名的函数只能在包级语法块中被声明，通过函数字面量（function literal），我们可绕过这一限制，在任何表达式中表示一个函数值。12345678910var visitAll func(items []string)visitAll = func(items []string) &#123; for _, item := range items &#123; if !seen[item] &#123; seen[item] = true visitAll(m[item]) order = append(order, item) &#125; &#125;&#125; 当匿名函数需要被递归调用时，我们必须首先声明一个变量（在上面的例子中，我们首先声明visitAll），再将匿名函数赋值给这个变量。如果不分成两部，函数字面量无法与visitAll绑定. 警告：捕获迭代变量这节极其重要！！！ 本节，将介绍Go词法作用域的一个陷阱。请务必仔细的阅读，弄清楚发生问题的原因。即使是经验丰富的程序员也会在这个问题上犯错误。考虑这个样一个问题：你被要求首先创建一些目录，再将目录删除。在下面的例子中我们用函数值来完成删除操作。下面的示例代码需要引入os包。为了使代码简单，我们忽略了所有的异常处理。 // …do some work…for _, rmdir := range rmdirs {rmdir() // clean up}你可能会感到困惑，为什么要在循环体中用循环变量d赋值一个新的局部变量，而不是像下面的代码一样直接使用循环变量dir。需要注意，下面的代码是错误的。12345678var rmdirs []func()for _, d := range tempDirs() &#123; dir := d // NOTE: necessary! os.MkdirAll(dir, 0755) // creates parent directories too rmdirs = append(rmdirs, func() &#123; os.RemoveAll(dir) &#125;)&#125; 问题的原因在于循环变量的作用域。在上面的程序中，for循环语句引入了新的词法块，循环变量dir在这个词法块中被声明。在该循环中生成的所有函数值都共享相同的循环变量。需要注意，函数值中记录的是循环变量的内存地址，而不是循环变量某一时刻的值。以dir为例，后续的迭代会不断更新dir的值，当删除操作执行时，for循环已完成，dir中存储的值等于最后一次迭代的值。这意味着，每次对os.RemoveAll的调用删除的都是相同的目录。通常，为了解决这个问题，我们会引入一个与循环变量同名的局部变量，作为循环变量的副本。比如下面的变量dir，虽然这看起来很奇怪，但却很有用。1234for _, dir := range tempDirs() &#123; dir := dir // declares inner dir, initialized to outer dir // ...&#125; 这个问题不仅存在基于range的循环，在下面的例子中，对循环变量i的使用也存在同样的问题：1234567dirs := tempDirs()for i := 0; i &lt; len(dirs); i++ &#123; os.MkdirAll(dirs[i], 0755) // OK rmdirs = append(rmdirs, func() &#123; os.RemoveAll(dirs[i]) // NOTE: incorrect! &#125;)&#125; 如果你使用go语句（第八章）或者defer语句（5.8节）会经常遇到此类问题。这不是go或defer本身导致的，而是因为它们都会等待循环结束后，再执行函数值。 注：for的词法作用域导致循环的时候，dir为同一个内存地址，传递给Println函数的是dir的值。123456789func main() &#123; c := []int&#123;1, 2, 3&#125; for _, v := range c &#123; defer func() &#123; fmt.Println(v) &#125;() &#125; fmt.Println("Over")&#125; 可变参数在声明可变参数函数时，需要在参数列表的最后一个参数类型之前加上省略符号“…”，这表示该函数会接收任意数量的该类型参数。1234567func sum(vals ...int) int &#123; total := 0 for _, val := range vals &#123; total += val &#125; return total&#125; 在函数体中,vals被看作是类型为[] int的切片。 方法尽管没有被大众所接受的明确的OOP的定义，从我们的理解来讲，一个对象其实也就是一个简单的值或者一个变量，在这个对象中会包含一些方法，而一个方法则是一个一个和特殊类型关联的函数。一个面向对象的程序会用方法来表达其属性和对应的操作，这样使用这个对象的用户就不需要直接去操作对象，而是借助方法来做这些事情。 方法声明123func (p Point) Distance(q Point) float64 &#123; return math.Hypot(q.X-p.X, q.Y-p.Y)&#125; 上面的代码里那个附加的参数p，叫做方法的接收器(receiver)，早期的面向对象语言留下的遗产将调用一个方法称为“向一个对象发送消息”。在Go语言中，我们并不会像其它语言那样用this或者self作为接收器；我们可以任意的选择接收器的名字。由于接收器的名字经常会被使用到，所以保持其在方法间传递时的一致性和简短性是不错的主意。这里的建议是可以使用其类型的第一个字母，比如这里使用了Point的首字母p。 接口在Go语言中，变量总是被一个定义明确的值初始化，即使接口类型也不例外。对于一个接口的零值就是它的类型和值的部分都是nil field value type nil value nil 一个接口值可以持有任意大的动态值。接口值可以使用＝＝和！＝来进行比较。两个接口值相等仅当它们都是nil值或者它们的动态类型相同并且动态值也根据这个动态类型的＝＝操作相等。 GoRoutines 和 channelsChannels和map类似，channel也一个对应make创建的底层数据结构的引用。复制一个channel或用于函数参数传递时，只是拷贝了一个channel引用，因此调用者和被调用者将引用同一channel对象。和其它的引用类型一样，channel的零值也是nil。两个相同类型的channel可以使用==运算符比较。如果两个channel引用的是相通的对象，那么比较的结果为真当一个channel被关闭后，再向该channel发送数据将导致panic异常。当一个被关闭的channel中已经发送的数据都被成功接收后，后续的接收操作将不再阻塞，它们会立即返回一个零值。 不带缓存的Channels基于无缓存Channels的发送和接收操作将导致两个goroutine做一次同步操作。因为这个原因，无缓存Channels有时候也被称为同步Channels。你并不需要关闭每一个channel。只要当需要告诉接收者goroutine，所有的数据已经全部发送时才需要关闭channel。不管一个channel是否被关闭，当它没有被引用时将会被Go语言的垃圾自动回收器回收。（不要将关闭一个打开文件的操作和关闭一个channel操作混淆。对于每个打开的文件，都需要在不使用的使用调用对应的Close方法来关闭文件。） 基于select的多路复用如果多个case同时就绪时，select会随机地选择一个执行，这样来保证每一个channel都有平等的被select的机会。123456789101112for &#123; select &#123; case &lt;-done: // Drain fileSizes to allow existing goroutines to finish. for range fileSizes &#123; // Do nothing. &#125; return case size, ok := &lt;-fileSizes: // ... &#125;&#125; 在结束之前我们需要把fileSizes channel中的内容“排”空，在channel被关闭之前，舍弃掉所有值。 基于共享变量的并发竞争条件一个函数在线性程序中可以正确地工作。如果在并发的情况下，这个函数依然可以正确地工 作的话，那么我们就说这个函数是并发安全的，并发安全的函数不需要额外的同步工作。我们可以把这 个概念概括为一个特定类型的一些方法和操作函数，如果这个类型是并发安全的话，那么所有它的访问 方法和操作就都是并发安全的。竞争条件指的是程序在多个goroutine交叉执行操作时，没有给出正确的结果。竞争条件是很恶劣的一种场景，因为这种问题会一直潜伏在你的程序里，然后在非常少见的时候蹦出来数据竞争的定义：数据竞争会在两个以上的goroutine并发访问相同的变量且至少其中一个为写操作时发生。根据上述定义，有三种方式可以避免数据竞争： 第一种方法是不要去写变量。 第二种避免数据竞争的方法是，避免从多个goroutine访问变量。1. 变量都被限定在了一个单独的goroutine中。 由于其它的goroutine不能够直接访问变量，它们只能使用一个channel来发送给指定的goroutine请求来查询更新变量。这也就是Go的口头禅“不要使用共享数据来通信；使用通信来共享数据”。一个提供对 一个指定的变量通过cahnnel来请求goroutine叫做这个变量的监控(monitor)goroutine。2.即使当一个变量无法在其整个生命周期内被绑定到一个独立的goroutine，绑定依然是并发问题的一个解 决方案。例如在一条流水线上的goroutine之间共享变量是很普遍的行为，在这两者间会通过channel来传输地址信息。（注： 串行channel） 第三种避免数据竞争的方法是允许很多goroutine去访问变量，但是在同一个时刻最多只有一个 goroutine在访问。这种方式被称为“互斥” Goroutines和线程每一个OS线程都有一个固定大小的内存块(一般会是2MB)来做栈，这个栈会用来存储当前正在被调用或挂 起(指在调用其它函数时)的函数的内部变量。一个goroutine会以一个很小的栈开始其生命周期，一般只需要2KB。一个goroutine的栈，和操作 系统线程一样，会保存其活跃或挂起的函数调用的本地变量，但是和OS线程不太一样的是一个goroutine 的栈大小并不是固定的；栈的大小会根据需要动态地伸缩。而goroutine的栈的最大值有1GB，比传统的 固定大小的线程栈要大得多， Goroutine调度OS线程会被操作系统内核调度。每几毫秒，一个硬件计时器会中断处理器，这会调用一个叫作scheduler 的内核函数。这个函数会挂起当前执行的线程并保存内存中它的寄存器内容，检查线程列表并决定下一 次哪个线程可以被运行，并从内存中恢复该线程的寄存器信息，然后恢复执行该线程的现场并开始执行 线程。因为操作系统线程是被内核所调度，所以从一个线程向另一个“移动”需要完整的上下文切换， 也就是说，保存一个用户线程的状态到内存，恢复另一个线程的到寄存器，然后更新调度器的数据结 构。这几步操作很慢，因为其局部性很差需要几次内存访问，并且会增加运行的cpu周期。 Go的运行时包含了其自己的调度器，这个调度器使用了一些技术手段，比如m:n调度，因为其会在n个操 作系统线程上多工(调度)m个goroutine。Go调度器的工作和内核的调度是相似的，但是这个调度器只关 注单独的Go程序中的goroutine(译注：按程序独立)。和操作系统的线程调度不同的是，Go调度器并不是用一个硬件定时器而是被Go语言”建筑”本身进行调度 的。例如当一个goroutine调用了time.Sleep或者被channel调用或者mutex操作阻塞时，调度器会使其进 入休眠并开始执行另一个goroutine直到时机到了再去唤醒第一个goroutine。因为因为这种调度方式不 需要进入内核的上下文，所以重新调度一个goroutine比调度一个线程代价要低得多。 包和工具有时候，一个中间的状态可能也是有用的，对于一小部分信任的包是可见的，但并不是对所有调用者都 可见。例如，当我们计划将一个大的包拆分为很多小的更容易维护的子包，但是我们并不想将内部的子 包结构也完全暴露出去。同时，我们可能还希望在内部子包之间共享一些通用的处理包，或者我们只是 想实验一个新包的还并不稳定的接口，暂时只暴露给一些受限制的用户使用。为了满足这些需求，Go语言的构建工具对包含internal名字的路径段的包导入路径做了特殊处理。这种 包叫internal包，一个internal包只能被和internal目录有同一个父目录的包所导入。]]></content>
      <categories>
        <category>Go学习小记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Go语言圣经</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[mongo数据库sharding学习记录]]></title>
    <url>%2F2016%2F12%2F09%2Fmongo%E6%95%B0%E6%8D%AE%E5%BA%93sharding%2F</url>
    <content type="text"><![CDATA[参考文章：http://www.runoob.com/mongodb/mongodb-sharding.html windows系统。mongo3.2版本 建立目录s0,s1,log,config 步骤一：启动Shard Server123.\bin\mongod.exe --port 27100 --dbpath=.\mongos\s0 --logpath=.\mongos\log\s0.log --logappend --journal --storageEngine=mmapv1 --shardsvr.\bin\mongod.exe --port 27101 --dbpath=.\mongos\s1 --logpath=.\mongos\log\s1.log --logappend --journal --storageEngine=mmapv1 --shardsvr 步骤二： 启动Config Server1.\bin\mongod.exe --port 27200 --dbpath=.\mongos\config --logpath=.\mongos\log\config.log --logappend --journal --storageEngine=mmapv1 --configsvr 步骤三： 启动Route Process1.\bin\mongos.exe --port 40000 --configdb localhost:27200 --logpath=.\mongos\log\router.log --chunkSize 1 注意: 我这里不加–configsvr就出现Surprised to discover that localhost:27200 does not believe it is a config server错误。 chunkSize太大的话，会导致插入很多很多数据后才分片。一开始没注意，以为设置错误没有分片。。。chunkSize以M为单位。 步骤四： 配置Sharding 连接路由服务器 1.\bin\mongo.exe admin --port 40000 设置分片服务器 12345db.runCommand(&#123; addshard:&quot;127.0.0.1:27100&quot; &#125;)db.runCommand(&#123; addshard:&quot;127.0.0.1:27101&quot; &#125;)db.runCommand(&#123; addshard:&quot;127.0.0.1:40000&quot; &#125;)或者sh.addShard(&quot;127.0.0.1:27100&quot;) 设置要分片的数据库 123db.runCommand(&#123; enablesharding:&quot;qdgame&quot; &#125;)或者：sh.enableSharding(&quot;qdgame&quot;) 关闭balancing 1sh.disableBalancing(&quot;qdgame.backpack&quot;) 设置分片collection的index 12use qdgamedb.backpack.ensureIndex(&#123;usrid:1,id:1&#125;) 设置要分片的collection 123db.runCommand(&#123; shardcollection: &quot;qdgame.backpack&quot;, key: &#123; usrid:1, id:1&#125;&#125;)或者sh.shardCollection(&quot;qdgame.backpack&quot;,&#123;usrid:1, id:1&#125;) 开启balancing 1sh.enableBalancing(&quot;qdgame.backpack&quot;) 注意：设置一定要在admin数据库下。]]></content>
      <categories>
        <category>数据库学习记录</category>
      </categories>
      <tags>
        <tag>mongo</tag>
        <tag>sharding</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[《Go语言圣经》学习小记（1）]]></title>
    <url>%2F2016%2F12%2F07%2F%E3%80%8AGo%E8%AF%AD%E8%A8%80%E5%9C%A3%E7%BB%8F%E3%80%8B%E5%AD%A6%E4%B9%A0%E5%B0%8F%E8%AE%B0%EF%BC%881%EF%BC%89%2F</url>
    <content type="text"><![CDATA[记录《Go语言圣经》学习笔记。（实为划重点） 顺序通信进程 （ communicating sequential processes ，缩写为CSP）。在CSP中，程序是一组中间没有共享状态的平行运行的处理过程，它们之间使用管道进行通信和控制同步。Go语言的官方博客 https://blog.golang.org 会不定期发布一些Go语言最好的实践文章，包括当前语言的发展状态、未来 的计划、会议报告和Go语言相关的各种会议的主题等信息（译注： http://talks.golang.org/ 包含了 官方收录的各种报告的讲稿）。 第一章 入门对map进行range循环时，其迭代顺序是不确定的，从实践来看，很可能每次运行都会有不一样的结果（译注：这是Go语言的设计者有意为之的，因为其底层实现不保证插入顺序和遍历顺序一致，也希望程序员不要依赖遍历时的顺序，所以干脆直接在遍历的时候做了随机化处理，醉了。补充：好像说随机序可以防止某种类型的攻击，虽然不太明白，但是感觉还蛮厉害的），来避免程序员在业务中依赖遍历时的顺序。map是用make函数创建的数据结构的一个引用。当一个map被作为参数传递给一个函数时，函数接收到的是一份引用的拷贝，虽然本身并不是一个东西，但因为他们指向的是同一块数据对象（译注：类似于C++里的引用传递，实际上指针是另一个指针了，但内部存的值指向同一块内存），所以你在函数里对map里的值进行修改时，原始的map内的值也会改变。 第二章 程序结构如果初始化表达式被省略，那么将用零值初始化该变量。 数值类型变量对应的零值是0，布尔类型变量对应的零值是false，字符串类型对应的零值是空字符串，接口或引用类型（包括slice、map、chan和函数）变量对应的零值是nil。数组或结构体等聚合类型对应的零值是每个元素或字段都是对应该类型的零值。var形式的声明语句往往是用于需要显式指定变量类型地方，或者因为变量稍后会被重新赋值而初始值无关紧要的地方。任何类型的指针的零值都是nil。。如果p != nil测试为真，那么p是指向某个有效变量。指针之间也是可以进行相等测试的，只有当它们指向同一个变量或全部是nil时才相等。每次调用new函数都是返回一个新的变量的地址，当然也可能有特殊情况：如果两个类型都是空的，也就是说类型的大小是0，例如struct{}和 [0]int,有可能有相同的地址（依赖具体的语言实现）（译注：请谨慎使用大小为0的类型，因为如果类型的大小为0的话，可能导致Go语言的自动垃圾回收器有不同的行为，具体请查看runtime.SetFinalizer函数相关文档）。 第三章 基础数据类型一个字符串是一个不可改变的字节序列。内置的len函数可以返回一个字符串中的字节数目（不是rune字符数目），索引操作s[i]返回第i个字节的字节值，i必须满足0 ≤ i&lt; len(s)条件约束。字符串的值是不可变的：一个字符串包含的字节序列永远不会被改变，当然我们也可以给一个字符串变量分配一个新字符串值。可以像下面这样将一个字符串追加到另一个字符串：123s := "left foot"t := ss += ", right foot" 这并不会导致原始的字符串值被改变，但是变量s将因为+=语句持有一个新的字符串值，但是t依然是包含原先的字符串值。Go语言的常量有个不同寻常之处。虽然一个常量可以有任意有一个确定的基础类型，例如int或float64，或者是类似time.Duration这样命名的基础类型，但是许多常量并没有一个明确的基础类型。编译器为这些没有明确的基础类型的数字常量提供比基础类型更高精度的算术运算。无类型的常量不仅可以提供更高的运算精度，而且可以直接用于更多的表达式而不需要显式的类型转换。例如math包中的Pi常量：1Pi = 3.14159265358979323846264338327950288419716939937510582097494459 //http://oeis.org/A000796 第四章 符合数据类型数组在数组字面值中，如果在数组的长度位置出现的是“…”省略号，则表示数组的长度是根据初始化值的个数来计算。数组的长度必须是常量表达式，因为数组的长度需要在编译阶段确定。12q := [...]int&#123;1, 2, 3&#125;fmt.Printf("%T\n", q) // "[3]int" 也可以指定一个索引和对应值列表的方式初始化，就像下面这样：12345678910type Currency intconst ( USD Currency = iota // 美元 EUR // 欧元 GBP // 英镑 RMB // 人民币)symbol := [...]string&#123;USD: "$", EUR: "€", GBP: "￡", RMB: "￥"&#125;fmt.Println(RMB, symbol[RMB]) // "3 ￥" 如果一个数组的元素类型是可以相互比较的，那么数组类型也是可以相互比较的，这时候我们可以直接通过==比较运算符来比较两个数组，只有当两个数组的所有元素都是相等的时候数组才是相等的。不相等比较运算符!=遵循同样的规则。(斩风注: 这里的比较仅指相等和不等。大于小于不包含在此类，数组长度类型必须相同)123456a := [2]int&#123;1, 2&#125;b := [...]int&#123;1, 2&#125;c := [2]int&#123;1, 3&#125;fmt.Println(a == b, a == c, b == c) // "true false false"d := [3]int&#123;1, 2&#125;fmt.Println(a == d) // compile error: cannot compare [2]int == [3]int slice一个slice是一个轻量级的数据结构，提供了访问数组子序列（或者全部）元素的功能，而且slice的底层确实引用一个数组对象。一个slice由三个部分构成：指针、长度和容量。指针指向第一个slice元素对应的底层数组元素的地址，要注意的是slice的第一个元素并不一定就是数组的第一个元素。（斩风注：slice可能是数组的中间部分。）长度对应slice中元素的数目；长度不能超过容量，容量一般是从slice的开始位置到底层数据的结尾位置。内置的len和cap函数分别返回slice的长度和容量。复制一个slice只是对底层的数组创建了一个新的slice别名。和数组不同的是，slice之间不能比较，因此我们不能使用==操作符来判断两个slice是否含有全部相等元素。不过标准库提供了高度优化的bytes.Equal函数来判断两个字节型slice是否相等（[]byte），但是对于其他类型的slice，我们必须自己展开每个元素进行比较。一个零值的slice等于nil。一个nil值的slice并没有底层数组。一个nil值的slice的长度和容量都是0，但是也有非nil值的slice的长度和容量也是0的，例如[]int{}或make([]int, 3)[3:]。与任意类型的nil值一样，我们可以用[]int(nil)类型转换表达式来生成一个对应类型slice的nil值。1234var s []int // len(s) == 0, s == nils = nil // len(s) == 0, s == nils = []int(nil) // len(s) == 0, s == nils = []int&#123;&#125; // len(s) == 0, s != nil 如果你需要测试一个slice是否是空的，使用len(s) == 0来判断，而不应该用s == nil来判断。内置的append函数可能使用比appendInt更复杂的内存扩展策略。因此，通常我们并不知道append调用是否导致了内存的重新分配，因此我们也不能确认新的slice和原始的slice是否引用的是相同的底层数组空间。同样，我们不能确认在原先的slice上的操作是否会影响到新的slice。因此，通常是将append返回的结果直接赋值给输入的slice变量。 练习 4.3： 重写reverse函数，使用数组指针代替slice。12345func reverseV2(s *[10]int) &#123; for i, j := 0, 9; i &lt; j; i, j = i+1, j-1 &#123; (*s)[i], (*s)[j] = (*s)[j], (*s)[i] &#125;&#125; 练习 4.4： 编写一个rotate函数，通过一次循环完成镟转。12345678910111213141516func forwardRotate(s []int, x int) &#123; mid := x k := mid for i := 0; i &lt; len(s); i++ &#123; s[i], s[k] = s[k], s[i] k++ if i == mid &#123; if k == len(s) &#123; return &#125; mid = k &#125; else if k == len(s) &#123; k = mid &#125; &#125;&#125; 练习 4.5： 写一个函数在原地完成消除[]string中相邻重复的字符串的操作。12345678910111213func noRepeatSide(s []string) []string &#123; count := len(s) for i := range s &#123; if i == len(s)-1 &#123; return s &#125; if s[i] == s[i+1] &#123; s = append(s[:i], s[i+1:]...) count-- &#125; &#125; return s&#125; Map虽然浮点数类型也是支持相等运算符比较的，但是将浮点数用做key类型则是一个坏的想法，正如第三章提到的，最坏的情况是可能出现的NaN和任何浮点数都不相等。对于V对应的value数据类型则没有任何的限制.map中的元素并不是一个变量，因此我们不能对map的元素进行取址操作.map上的大部分操作，包括查找、删除、len和range循环都可以安全工作在nil值的map上，它们的行为和一个空的map类似。但是向一个nil值的map存入元素将导致一个panic异常.在向map存数据前必须先创建map。和slice一样，map之间也不能进行相等比较；唯一的例外是和nil进行比较。要判断两个map是否包含相同的key和value，我们必须通过一个循环实现.如果结构体的全部成员都是可以比较的，那么结构体也是可以比较的，那样的话两个结构体将可以使用==或!=运算符进行比较.Go语言有一个特性让我们只声明一个成员对应的数据类型而不指名成员的名字；这类成员就叫匿名成员。匿名成员的数据类型必须是命名的类型或指向一个命名的类型的指针。下面的代码中，Circle和Wheel各自都有一个匿名成员。我们可以说Point类型被嵌入到了Circle结构体，同时Circle类型被嵌入到了Wheel结构体。12345678type Circle struct &#123;PointRadius int&#125;type Wheel struct &#123;CircleSpokes int&#125; 得益于匿名嵌入的特性，我们可以直接访问叶子属性而不需要给出完整的路径：12345var w Wheelw.X = 8 // equivalent to w.Circle.Point.X = 8w.Y = 8 // equivalent to w.Circle.Point.Y = 8w.Radius = 5 // equivalent to w.Circle.Radius = 5w.Spokes = 20 为什么要嵌入一个没有任何子成员类型的匿名成员类型呢？答案是匿名类型的方法集。简短的点运算符语法可以用于选择匿名成员嵌套的成员，也可以用于访问它们的方法。实际上，外层的结构体不仅仅是获得了匿名成员类型的所有成员，而且也获得了该类型导出的全部的方法。这个机制可以用于将一个有简单行为的对象组合成有复杂行为的对象。组合是Go语言中面向对象编程的核心.]]></content>
      <categories>
        <category>Go学习小记</category>
      </categories>
      <tags>
        <tag>笔记</tag>
        <tag>Go语言圣经</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Error handling and Go (翻译)]]></title>
    <url>%2F2016%2F12%2F05%2F%E9%94%99%E8%AF%AF%E5%A4%84%E7%90%86%E5%92%8CGo%2F</url>
    <content type="text"><![CDATA[本篇文章来自《The Go Blog》。文章地址为https://blog.golang.org/error-handling-and-go下面是在下的翻译。因为看英文看完就忘，所以翻译翻译，聊以自慰。 错误处理和Go2011年7月12日 引言如果你写过Go的代码，你可能已经遇到了内置的error类型。Go的代码使用error表示异常状态。例如os.Open函数打开文件失败的时候，返回一个不为nil的error值。1func Open(name string) (file *File, err error) 下面的代码使用os.Open打开一个文件。如果出现一个error,它会调用log.Fatal来打印出错误结束。12345f, err := os.Open("filename.ext")if err != nil &#123; log.Fatal(err)&#125;// do something with the open *File f 在Go中，你仅需要知道这些关于error类型的知识，就能做很多事情了，但是在这篇文章中我们将仔细研究error，并讨论在Go中的一些好的错误处理的实例 error 类型error类型是一个接口(interface)类型。一个error变量代表任意一个能将自己描绘成字符串的值。这个是接口的定义123type error interface &#123; Error() string&#125; error类型如同其他所有内置类型是在universe block(The universe block encompasses all Go source text.)中预声明（predeclare）的。最常使用的error实例是error包中未导出（export）的errorString类型。12345678// errorString is a trivial implementation of error.type errorString struct &#123; s string&#125;func (e *errorString) Error() string &#123; return e.s&#125; 你可以使用errors.New函数来构建一个这样的值。它接受一个字符串，将之转成errors.errorString，并返回error值1234// New returns an error that formats as the given text.func New(text string) error &#123; return &amp;errorString&#123;text&#125;&#125; 这是你可能会使用的errors.New的情况：123456func Sqrt(f float64) (float64, error) &#123; if f &lt; 0 &#123; return 0, errors.New("math: square root of negative number") &#125; // implementation&#125; 使用一个负数参数来调用Sqrt，会得到一个非nil的error值（具体的表示是一个errors.errorString值）。调用者能通过error类型的Error方法获取错误字符串(“math: square root of…”)，或者就直接输出它：1234f, err := Sqrt(-1)if err != nil &#123; fmt.Println(err)&#125; fmt包通过调用它的Error()方法格式化error类型的值。这个是错误的实现总结上下文的方法。错误应该由os.Open格式化返回为”open /etc/passwd: permission denied,” ,而不仅仅是”permission denied.”由Sqrt返回的错误缺少了关于无效参数的信息。在fmt包中有个有用的函数Errorf,用于增加这个信息。它根据 Printf规则来格式化字符串，并返回一个由errors.New创建的error类型。123if f &lt; 0 &#123; return 0, fmt.Errorf("math: square root of negative number %g", f)&#125; 在许多情况下fmt.Errorf已经足够 ，但是既然error是一个interface，你可以使用任意的数据结构作为error，让调用者来检查错误的详细信息。举个例子，我们假想的调用也许想重新使用这个无效参数来调用Sqrt。我们能通过定义一个新的error的实现完成这个目标，而不是使用errors.errorString：12345type NegativeSqrtError float64func (f NegativeSqrtError) Error() string &#123; return fmt.Sprintf("math: square root of negative number %g", float64(f))&#125; 复杂的调用可以使用类型断言（type assertion）来检查NegativeSqrtError并特别处理，当调用者将error传递给fmt.Println或者log.Fatal的时候，不会有任何行为上的变化。再举个例子，当json.Decode函数解析一个JSON blob遇到语法错误时，返回一个json包中指定的SyntaxError类型。123456type SyntaxError struct &#123; msg string // description of error Offset int64 // error occurred after reading Offset bytes&#125;func (e *SyntaxError) Error() string &#123; return e.msg &#125; Offset字段甚至不会在error默认的格式化中出现，但是调用者可以使用它，添加文件和行信息到到error消息中。1234567if err := dec.Decode(&amp;val); err != nil &#123; if serr, ok := err.(*json.SyntaxError); ok &#123; line, col := findLine(f, serr.Offset) return fmt.Errorf("%s:%d:%d: %v", f.Name(), line, col, err) &#125; return err&#125; （这是来自Camlistore项目的真实代码的省略的简化版本）error接口仅仅需要Error方法；特殊的error实现可能需要其他的方法。例如，net包中返回error类型的错误，遵循了通常的惯例，但是一些error的实现通过net.Error接口定义了其他方法：1234567package nettype Error interface &#123; error Timeout() bool // Is the error a timeout? Temporary() bool // Is the error temporary?&#125; 客户端代码可以使用类型断言（type assertion）来测试，然后从永久性错误中区分短暂的的网络错误。例如，一个网络爬虫也许会休眠并重试当它遇到一个零时性错误并放弃其他的。1234567if nerr, ok := err.(net.Error); ok &amp;&amp; nerr.Temporary() &#123; time.Sleep(1e9) continue&#125;if err != nil &#123; log.Fatal(err)&#125; 简化重复的错误处理在Go中，错误处理非常重要。语言的设计和约定鼓励你在发生错误的时候明确检查错误（和其他语言使用抛出错误并获取错误（ throwing exceptions and sometimes catching them ）的惯例不一样）。在有些情况下，这使你的Go代码冗余，但是幸运的是，你可以使用一些技巧来最少的重复错误处理。思考一个使用HTTP处理器的App Engine应用，从数据库中检索一条记录并使用模板格式化。12345678910111213141516func init() &#123; http.HandleFunc("/view", viewRecord)&#125;func viewRecord(w http.ResponseWriter, r *http.Request) &#123; c := appengine.NewContext(r) key := datastore.NewKey(c, "Record", r.FormValue("id"), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil &#123; http.Error(w, err.Error(), 500) return &#125; if err := viewTemplate.Execute(w, record); err != nil &#123; http.Error(w, err.Error(), 500) &#125;&#125; 这个函数处理由datastore.Get函数和viewTemplate的Execute方法产生的错误。在这两个错误中，它用HTTP状态码500(“Internal Server Error”)来向用户展现一个简单的错误信息。这段代码看起来是可管理的，但是添加了多余的HTTP处理器，并以许多相同的错误处理代码结束。为了减少重复，我们可以定义我们自己的HTTP appHandler类型来包含error并返回值。1type appHandler func(http.ResponseWriter, *http.Request) error 然后，我们修改我们的viewRecord 函数来返回错误：123456789func viewRecord(w http.ResponseWriter, r *http.Request) error &#123; c := appengine.NewContext(r) key := datastore.NewKey(c, "Record", r.FormValue("id"), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil &#123; return err &#125; return viewTemplate.Execute(w, record)&#125; 这和原始的版本相似，但是http包不能理解返回error的函数。为了修正，我们在appHandler上实现了http.Handler接口的ServeHTTP方法：12345func (fn appHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) &#123; if err := fn(w, r); err != nil &#123; http.Error(w, err.Error(), 500) &#125;&#125; ServeHTTP方法调用appHandler函数并且向用户显示错误（如果有的话）。注意这个方法的接收者，fn，是一个函数。（Go可以这样做！）方法调用函数通过调用表达式fn(w, r)中的接收者。现在，当使用http包注册viewRecord的时候，我们使用Handle函数（而不是HandleFunc）appHandler作为http.Handler（而不是http.HandlerFunc）123func init() &#123; http.Handle("/view", appHandler(viewRecord))&#125; 通过基本架构中的错误处理，我们可以使它更加的用户友好。相比仅仅展示错误的字符串，更好的方法是给用户简单的错误消息并附加适合的HTTP状态码，同时在App Engine开发者控制台记录完整的错误用于调试。为了做到这点，我们创建一个appError 结构体，包含一个error类型和一些其他字段12345type appError struct &#123; Error error Message string Code int&#125; 接下来，我们修改appHandler类型以便返回*appError值：1type appHandler func(http.ResponseWriter, *http.Request) *appError （通常，不使用error，而是使用具体的error类型进行传递的做法是错误的，原因会在Go FAQ中讨论，不过在这里是正确的，因为ServeHTTP是唯一看到这个值并且使用其内容的地方。） 为了使appHandler的ServeHTTP方法向用户显示appError的消息和正确的HTTP状态码，并向开发者记录完整的Error： 1234567 func (fn appHandler) ServeHTTP(w http.ResponseWriter, r *http.Request) &#123; if e := fn(w, r); e != nil &#123; // e is *appError, not os.Error. c := appengine.NewContext(r) c.Errorf("%v", e.Error) http.Error(w, e.Message, e.Code) &#125;&#125; 最后，我们更新viewRecord函数，并使它遇到错误的时候返回更多的上下文： 123456789101112 func viewRecord(w http.ResponseWriter, r *http.Request) *appError &#123; c := appengine.NewContext(r) key := datastore.NewKey(c, "Record", r.FormValue("id"), 0, nil) record := new(Record) if err := datastore.Get(c, key, record); err != nil &#123; return &amp;appError&#123;err, "Record not found", 404&#125; &#125; if err := viewTemplate.Execute(w, record); err != nil &#123; return &amp;appError&#123;err, "Can't display record", 500&#125; &#125; return nil&#125; 这个版本的viewRecord和原始版本的程度相同，但是现在每一行都有特别的意思，并且，我们提供更加友好的用户体验。 这还没结束；我们将会在我们的应用中优化错误处理。一些想法： 给予每个错误处理一个漂亮的HTML模板 当用户是管理员时，将stack trace写到HTTP回应中，使debug更加简单 为appError写一个构建函数，用于存储stack trace，以便调试 在appHandler中发生panic时recover，将错误作为“危险”写入开发者控制台，并用户“发生了一个严重的错误”。 这是避免向用户暴露由于编程错误引起的不可预测的错误的信息的一个很好的想法。参看Defer, Panic, and Recover 文章获取更多细节。 总结适合的错误处理是一个好的软件的基本需求。根据本文所讨论的技术，你应该能够写出更可靠且更简洁的Go代码 Andrew Gerrand 著]]></content>
      <categories>
        <category>Go学习小记</category>
      </categories>
      <tags>
        <tag>翻译</tag>
        <tag>错误处理</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[我的Redis初次实战]]></title>
    <url>%2F2016%2F09%2F03%2F%E6%88%91%E7%9A%84Redis%E5%88%9D%E6%AC%A1%E5%AE%9E%E6%88%98%2F</url>
    <content type="text"><![CDATA[因为各种原因，我必须在windows上进行服务器开发，所以我需要在windows上运行redis，即使《redis in action》上明确写着不推荐在windows上使用redis。我在windows上使用的redis是从 https://github.com/dmajkic/redis/downloads 获取的。我使用redis的桌面客户端为Redis Desktop Manager。使用的原因仅仅是第一个搜到的客户端就是他且没有让我讨厌的地方，就继续用了。软件地址https://redisdesktop.com/download。极力推荐《redis实战》。从第一章开始，在介绍什么是redis，有什么用，与其他数据库有什么区别之后，就开始从一个项目开始，演示如何使用redis。讲的第一个项目是对文章进行投票，这让我的回忆起我的大学的第一个项目–一个投票系统的实现。在看完这一章之后，我对redis有了个初步了解，并将在这一章学到的知识，运用到我的实际工作的一个小项目中：解析短信回执的xml，统计回执中的信息，统计用户的某个活动发送的短信各种状态的数目。解析后的xml数据大致如下123456type Message struct &#123; PhoneNum string State string UserID int ActivityID int&#125; 本项目是解析一个xml文件，得到其中的信息，进行统计，返回统计的结果。本来可以将数据使用Map存储在内存中，等所有的信息统计后，将Map中的信息输出就可以了，但是这个项目以后要扩展成，需要将内存的数据进行持久化处理，定时过期数据和多服务器主从同步数据，所以使用redis无疑是最好的选择。我仿造《redis实战》第一章的编程方法，对程序进行了改造。设定了： user集合： 存储接收到的xml中用户id的集合。集合内的元素类似{1,2,3} user_x_acitvity: 存储用户ID为x的活动id的集合，user_1_acitvity集合内的元素类似{1,2,3} user_x_acitvity_y: 存储用户ID为x，活动ID为y的手机号码信息。user_1_acitvity_1集合内的元素类似{“15952010343，DELIVRD”}，元素的值为”phoneNum,status”的组合通过user集合找到有哪些用户收到了回执，通过user_x_acitvity记录用户的哪些活动在回执的记录中。并通过user_x_acitvity_y找到属于此活动的手机号码的状态。看完《redis实战》第一章最大的收获就是设定set的名字。可以通过设定set以特定的名字，来索引到特定的信息。具体的程序代码在：https://github.com/qwendy/handleFeedback123456789101112131415161718192021222324252627282930func (rc *redisContainer) pushYiMeiXMLData(message YiMeiMessage) &#123; activityID := message.Seqid &gt;&gt; 16 userID := message.Seqid - (activityID &lt;&lt; 16) // 用户的集合。设置接收到的用户的集合 rc.client.SAdd("user", userID) // 设置某个用户的活动集合 userActivitySet := fmt.Sprintf("user:%d", userID) rc.client.SAdd(userActivitySet, activityID) // 活动的手机号码状态集合 activityPhoneSet := fmt.Sprintf("user_%d_activity_%d", userID, activityID) // 手机号码和状态 phoneStatus := fmt.Sprintf("%s,%s", message.PhoneNum, message.State) rc.client.SAdd(activityPhoneSet, phoneStatus)&#125;func (rc *redisContainer) Print() &#123; for _, userID := range rc.client.SMembers("user").Val() &#123; fmt.Printf("user:%s \n", userID) userActivitySet := fmt.Sprintf("user:%s", userID) for _, activityID := range rc.client.SMembers(userActivitySet).Val() &#123; fmt.Printf("activityID:%s \n", activityID) activityPhoneSet := fmt.Sprintf("user_%s_activity_%s", userID, activityID) for _, phoneStatus := range rc.client.SMembers(activityPhoneSet).Val() &#123; fmt.Printf("phoneStatus:%s ", phoneStatus) &#125; fmt.Printf("\n") &#125; &#125;&#125;]]></content>
      <categories>
        <category>数据库学习记录</category>
      </categories>
      <tags>
        <tag>redis</tag>
        <tag>实践</tag>
      </tags>
  </entry>
</search>
